{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0139584-cf56-4eff-a1e8-b5c1b64bf5c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:13.123909Z",
     "start_time": "2025-07-13T13:16:13.115285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the Dataset from detailed_listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a292dd7d-09ae-454a-ba92-1b79013e2ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:13.195021Z",
     "start_time": "2025-07-13T13:16:13.192380Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b9a77f6-1cd1-4442-91e3-6068cf7efc0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:13.760311Z",
     "start_time": "2025-07-13T13:16:13.248248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id  price\n",
      "0                     3176  105.0\n",
      "1                     9991  135.0\n",
      "2                    14325   75.0\n",
      "3                    16644   77.0\n",
      "4                    17904   40.0\n",
      "...                    ...    ...\n",
      "13940  1376348748790549852  107.0\n",
      "13941  1376356410353693375  103.0\n",
      "13942  1376569769868596901   59.0\n",
      "13943  1376576995944779676  100.0\n",
      "13944  1376671293707752704   71.0\n",
      "\n",
      "[8898 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv(\"detailed_listings_berlin.csv\")\n",
    "\n",
    "# Clean 'price' column by removing $ and , then convert to float\n",
    "df[\"price\"] = df[\"price\"].replace(r'[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Remove rows where 'price' is NaN (if any remain after conversion)\n",
    "df = df[df[\"price\"].notna()]\n",
    "\n",
    "# Check resulting shape\n",
    "print(df[[\"id\",\"price\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeabc3c-1c2f-435d-9571-744945fddd13",
   "metadata": {},
   "source": [
    "### Help function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1172e50-6455-45e5-8b7a-d2d7b3b54551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:13.823918Z",
     "start_time": "2025-07-13T13:16:13.820546Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_amenities_at_index(df, index):\n",
    "    raw_string = df.loc[index, \"amenities\"]\n",
    "    amenities_list = json.loads(raw_string)\n",
    "    return amenities_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3af48-85dd-4b2b-b370-fef4a4613fdc",
   "metadata": {},
   "source": [
    "### Refridgerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf88ff2-a06c-4cd7-9053-ecc1c732d7bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:13.878234Z",
     "start_time": "2025-07-13T13:16:13.876102Z"
    }
   },
   "outputs": [],
   "source": [
    "# First make price numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0282d7bd-e43b-4f53-9f27-1a33909176a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:13.934403Z",
     "start_time": "2025-07-13T13:16:13.932419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create new columns based on \"amenities\",\"description\",\"name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb26ae9-5e87-4002-9334-78c52be7e204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:14.019931Z",
     "start_time": "2025-07-13T13:16:14.005512Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_refrigerator_columns(df):\n",
    "    brand_column_names = {\n",
    "        'lg': 'refrigerator_lg',\n",
    "        'siemens': 'refrigerator_siemens',\n",
    "        'gaggenau': 'refrigerator_gaggenau',\n",
    "        'electrolux': 'refrigerator_electrolux',\n",
    "        'liebherr': 'refrigerator_liebherr',\n",
    "        'bosch': 'refrigerator_bosch',\n",
    "        'miele': 'refrigerator_miele',\n",
    "        'boomann': 'refrigerator_bomann',\n",
    "        'sharp': 'refrigerator_sharp',\n",
    "        'haier': 'refrigerator_haier',\n",
    "        'whirlpool': 'refrigerator_whirlpool',\n",
    "        'aeg': 'refrigerator_aeg',\n",
    "        'ikea': 'refrigerator_ikea',\n",
    "        'amazon': 'refrigerator_amazon',\n",
    "        'samsung': 'refrigerator_samsung',\n",
    "        'elektrolux': 'refrigerator_electrolux',\n",
    "        'beko': 'refrigerator_beko',\n",
    "        'beco': 'refrigerator_beko',\n",
    "        'smeg': 'refrigerator_smeg',\n",
    "        'severin': 'refrigerator_severin',\n",
    "        'teka': 'refrigerator_teka',\n",
    "        'zanussi': 'refrigerator_zanussi',\n",
    "        'panasonic': 'refrigerator_panasonic',\n",
    "        'vestel': 'refrigerator_vestel',\n",
    "        'gorenje': 'refrigerator_gorenje',\n",
    "        'diemens': 'refrigerator_siemens',\n",
    "        'bomann': 'refrigerator_bomann',\n",
    "        'amica': 'refrigerator_amica',\n",
    "        'neff': 'refrigerator_neff',\n",
    "    }\n",
    "\n",
    "    new_cols = {\n",
    "        \"has_refrigerator\": pd.Series(False, index=df.index),\n",
    "        \"refrigerator_shared\": pd.Series(False, index=df.index),\n",
    "    }\n",
    "    \n",
    "    for col in set(brand_column_names.values()):\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    brand_keys_lower = {k.lower(): v for k, v in brand_column_names.items()}\n",
    "    fridge_terms = [\"refrigerator\", \"refridgerator\", \"fridge\", \"kühlschrank\",\"kuehlschrank\"]\n",
    "\n",
    "    shared_fridge_pattern = re.compile(\n",
    "        r\"\\b(shared fridge|shared refrigerator|community fridge|community refridgerator|geteilter kühlschrank|geteilter kuehlschrank)\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Detect has_refrigerator\n",
    "        if any(term in a for term in fridge_terms for a in amenities_lower):\n",
    "            new_cols[\"has_refrigerator\"].at[idx] = True\n",
    "\n",
    "        # ✅ Detect refrigerator_shared\n",
    "        if any(shared_fridge_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"refrigerator_shared\"].at[idx] = True\n",
    "\n",
    "        # ✅ Detect brand-specific columns\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if any(term in amenity_lower for term in fridge_terms):\n",
    "                for brand_key_lower, col_name in brand_keys_lower.items():\n",
    "                    if brand_key_lower in amenity_lower:\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62906897-0075-4889-bcd4-b78c533b7ae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:14.104225Z",
     "start_time": "2025-07-13T13:16:14.099980Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_refrigerator_brands(df):\n",
    "    # Identify all refrigerator brand columns in the DataFrame\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"refrigerator_\") and col != \"has_refrigerator\"]\n",
    "\n",
    "    # Count the number of True values per column\n",
    "    brand_counts = df[brand_columns].sum().sort_values(ascending=False)\n",
    "\n",
    "    # Return as a clean DataFrame for inspection or reporting\n",
    "    return brand_counts.reset_index().rename(columns={\"index\": \"brand_column\", 0: \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eed8da0f-df4a-4fcc-97f9-9eb561facd2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:14.157786Z",
     "start_time": "2025-07-13T13:16:14.154249Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_refrigerators_with_and_without_brand(df):\n",
    "    # Identify all refrigerator brand columns\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"refrigerator_\") and col != \"has_refrigerator\"]\n",
    "\n",
    "    # Boolean series: at least one brand column is True\n",
    "    has_brand = df[brand_columns].any(axis=1)\n",
    "\n",
    "    # Count:\n",
    "    # Listings with refrigerator and with brand\n",
    "    with_brand = ((df[\"has_refrigerator\"]) & (has_brand)).sum()\n",
    "\n",
    "    # Listings with refrigerator and without brand\n",
    "    without_brand = ((df[\"has_refrigerator\"]) & (~has_brand)).sum()\n",
    "\n",
    "    return {\"with_brand\": int(with_brand), \"without_brand\": int(without_brand)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90167ba6-97e4-4800-8fe4-0f0e2a3dc2ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:14.624292Z",
     "start_time": "2025-07-13T13:16:14.224641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_brand': 396, 'without_brand': 6433}\n",
      "               brand_column  count\n",
      "0      refrigerator_siemens     72\n",
      "1        refrigerator_bosch     66\n",
      "2        refrigerator_miele     35\n",
      "3          refrigerator_aeg     33\n",
      "4     refrigerator_liebherr     29\n",
      "5      refrigerator_samsung     26\n",
      "6         refrigerator_smeg     23\n",
      "7    refrigerator_whirlpool     21\n",
      "8         refrigerator_ikea     13\n",
      "9         refrigerator_neff     11\n",
      "10          refrigerator_lg     11\n",
      "11       refrigerator_amica     10\n",
      "12        refrigerator_beko      9\n",
      "13  refrigerator_electrolux      8\n",
      "14     refrigerator_gorenje      7\n",
      "15     refrigerator_severin      4\n",
      "16      refrigerator_vestel      3\n",
      "17    refrigerator_gaggenau      3\n",
      "18       refrigerator_haier      3\n",
      "19       refrigerator_sharp      3\n",
      "20      refrigerator_bomann      3\n",
      "21     refrigerator_zanussi      2\n",
      "22      refrigerator_amazon      1\n",
      "23   refrigerator_panasonic      1\n",
      "24        refrigerator_teka      1\n",
      "25      refrigerator_shared      0\n"
     ]
    }
   ],
   "source": [
    "df = create_refrigerator_columns(df)\n",
    "brand_counts_df = count_refrigerator_brands(df)\n",
    "result = count_refrigerators_with_and_without_brand(df)\n",
    "print(result)\n",
    "print(brand_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa6c8e36-4d56-41f4-8bcf-16e802d5709d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:14.683512Z",
     "start_time": "2025-07-13T13:16:14.681396Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set index to check\n",
    "test_index = 77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95da279b-45b4-4eb5-a75d-2e1bbe83941a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:14.779466Z",
     "start_time": "2025-07-13T13:16:14.739963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 5375 | Displaying amenities and detected refrigerator brand(s) ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                amenities  has_refrigerator  refrigerator_gorenje\n",
      "5375  [\"Drying rack for clothing\", \"Shared backyard \\u2013 Fully fenced\", \"Dishes and silverware\", \"Bose sound system with aux\", \"Bed linens\", \"Books and reading material\", \"Hangers\", \"TV\", \"Wifi\", \"Coffee\", \"Dishwasher\", \"Freezer\", \"Cooking basics\", \"First aid kit\", \"Essentials\", \"Blender\", \"Hair dryer\", \"Extra pillows and blankets\", \"Heating\", \"Hot water kettle\", \"Self check-in\", \"Lockbox\", \"Kitchen\", \"Outdoor furniture\", \"Iron\", \"Wine glasses\", \"Washer\", \"Smoke alarm\", \"Hot water\", \"Room-darkening shades\", \"Baking sheet\", \"Oven\", \"Gorenje refrigerator\", \"Courtyard view\", \"Gorenje electric stove\", \"Toaster\", \"Dining table\"]              True                  True\n"
     ]
    }
   ],
   "source": [
    "# Identify refrigerator brand columns (excluding 'has_refrigerator')\n",
    "refrigerator_columns = [col for col in df.columns if col.startswith(\"refrigerator_\") and col != \"has_refrigerator\"]\n",
    "\n",
    "# Find all indices where any brand column is True\n",
    "indices_with_brand = df[df[refrigerator_columns].any(axis=1)].index\n",
    "\n",
    "# Take the first available index among those rows\n",
    "index_to_check = indices_with_brand[test_index]  # or loop over more if you wish\n",
    "\n",
    "# Filter to only the columns with True for this index\n",
    "true_brand_columns = [col for col in refrigerator_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display amenities, has_refrigerator, and only the brand columns that are True\n",
    "columns_to_display = [\"amenities\", \"has_refrigerator\"] + true_brand_columns\n",
    "\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected refrigerator brand(s) ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961b0fc-0391-4b73-93af-f1fe0723637a",
   "metadata": {},
   "source": [
    "### Oven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6a8bfe7-bd95-4e2a-9489-d2aecc888485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:14.839429Z",
     "start_time": "2025-07-13T13:16:14.833492Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_oven_columns(df):\n",
    "    # ✅ Clean trade oven brands only (adapted list, expand as needed)\n",
    "    brand_column_names = {\n",
    "        'bosch': 'oven_bosch',\n",
    "        'miele': 'oven_miele',\n",
    "        'siemens': 'oven_siemens',\n",
    "        'aeg': 'oven_aeg',\n",
    "        'neff': 'oven_neff',\n",
    "        'gaggenau': 'oven_gaggenau',\n",
    "        'smeg': 'oven_smeg',\n",
    "        'whirlpool': 'oven_whirlpool',\n",
    "        'electrolux': 'oven_electrolux',\n",
    "        'zanussi': 'oven_zanussi',\n",
    "        'beko': 'oven_beko',\n",
    "        'ikea': 'oven_ikea',\n",
    "        'haier': 'oven_haier',\n",
    "        'panasonic': 'oven_panasonic',\n",
    "        'teka': 'oven_teka',\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_oven\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in set(brand_column_names.values()):\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Lowercase brand mapping\n",
    "    brand_keys_lower = {k.lower(): v for k, v in brand_column_names.items()}\n",
    "    oven_terms = [\"oven\", \"backofen\", \"forno\"]\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Set has_oven if any oven term found\n",
    "        if any(any(term in a for term in oven_terms) for a in amenities_lower):\n",
    "            new_cols[\"has_oven\"].at[idx] = True\n",
    "\n",
    "        # Set brand columns if oven term + brand in the same amenity\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if any(term in amenity_lower for term in oven_terms):\n",
    "                for brand_key_lower, col_name in brand_keys_lower.items():\n",
    "                    if brand_key_lower in amenity_lower:\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    # Add to df\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "263cfaa3-ea94-480c-ae6f-960359491cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:14.896076Z",
     "start_time": "2025-07-13T13:16:14.889880Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_oven_brands(df):\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"oven_\") and col != \"has_oven\"]\n",
    "    brand_counts = df[brand_columns].sum().sort_values(ascending=False)\n",
    "    return brand_counts.reset_index().rename(columns={\"index\": \"brand_column\", 0: \"count\"})\n",
    "\n",
    "def count_ovens_with_and_without_brand(df):\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"oven_\") and col != \"has_oven\"]\n",
    "    has_brand = df[brand_columns].any(axis=1)\n",
    "    with_brand = ((df[\"has_oven\"]) & (has_brand)).sum()\n",
    "    without_brand = ((df[\"has_oven\"]) & (~has_brand)).sum()\n",
    "    return {\"with_brand\": int(with_brand), \"without_brand\": int(without_brand)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15098ce2-eb63-4dc7-a9e5-e1013bbbf8fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:15.300461Z",
     "start_time": "2025-07-13T13:16:14.953982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_brand': 260, 'without_brand': 4531}\n",
      "       brand_column  count\n",
      "0        oven_bosch     60\n",
      "1      oven_siemens     52\n",
      "2        oven_miele     52\n",
      "3          oven_aeg     31\n",
      "4         oven_neff     20\n",
      "5         oven_ikea     17\n",
      "6     oven_gaggenau      8\n",
      "7         oven_smeg      6\n",
      "8    oven_whirlpool      4\n",
      "9      oven_zanussi      4\n",
      "10        oven_beko      3\n",
      "11  oven_electrolux      2\n",
      "12        oven_teka      1\n",
      "13   oven_panasonic      0\n",
      "14       oven_haier      0\n"
     ]
    }
   ],
   "source": [
    "df = create_oven_columns(df)\n",
    "\n",
    "# Get counts\n",
    "oven_brand_counts_df = count_oven_brands(df)\n",
    "oven_counts = count_ovens_with_and_without_brand(df)\n",
    "\n",
    "print(oven_counts)\n",
    "print(oven_brand_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f5b6e49-9fa3-4189-9ede-9af9eda70c7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:15.386020Z",
     "start_time": "2025-07-13T13:16:15.379382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 390 | Displaying amenities and detected oven brand(s) ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  amenities  has_oven  oven_siemens\n",
      "390  [\"Bathtub\", \"Free dryer \\u2013 In unit\", \"Drying rack for clothing\", \"Dishes and silverware\", \"Bed linens\", \"Siemens electric stove\", \"Paid street parking off premises\", \"HDTV\", \"Hangers\", \"Wifi\", \"Dishwasher\", \"Cleaning products\", \"JVC sound system with Bluetooth and aux\", \"Coffee maker: drip coffee maker\", \"Cooking basics\", \"Essentials\", \"Bauknecht refrigerator\", \"Hair dryer\", \"Extra pillows and blankets\", \"Hot water kettle\", \"Clothing storage: closet and wardrobe\", \"Central heating\", \"Kitchen\", \"Single level home\", \"Iron\", \"Wine glasses\", \"Smoke alarm\", \"Body soap\", \"Room-darkening shades\", \"Hot water\", \"Baking sheet\", \"Private entrance\", \"Dining table\", \"Toaster\", \"Free washer \\u2013 In unit\", \"Siemens single oven\", \"Microwave\"]      True          True\n"
     ]
    }
   ],
   "source": [
    "# Identify oven brand columns\n",
    "oven_columns = [col for col in df.columns if col.startswith(\"oven_\") and col != \"has_oven\"]\n",
    "\n",
    "# Get indices where any oven brand was detected\n",
    "indices_with_oven_brand = df[df[oven_columns].any(axis=1)].index\n",
    "\n",
    "# Select the test index for inspection (adjust as needed)\n",
    "test_index = 9 # or another index for targeted inspection\n",
    "index_to_check = indices_with_oven_brand[test_index]\n",
    "\n",
    "# Filter columns with True for this index\n",
    "true_oven_columns = [col for col in oven_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for double-check\n",
    "columns_to_display = [\"amenities\", \"has_oven\"] + true_oven_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected oven brand(s) ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10468613-102e-48ff-b68b-5d860c3e9f2a",
   "metadata": {},
   "source": [
    "### Stove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1197cceb-ab0a-4795-b70e-6a84f9a09804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:15.524788Z",
     "start_time": "2025-07-13T13:16:15.517766Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_stove_columns(df):\n",
    "    # ✅ Stove types detection patterns\n",
    "    stove_types_patterns = {\n",
    "        \"stove_electric\": r\"\\belectric\\b\",\n",
    "        \"stove_induction\": r\"\\binduction\\b\",\n",
    "        \"stove_gas\": r\"\\bgas\\b\",\n",
    "    }\n",
    "\n",
    "    # ✅ Stove brands to detect\n",
    "    brand_column_names = {\n",
    "        'bosch': 'stove_bosch',\n",
    "        'miele': 'stove_miele',\n",
    "        'siemens': 'stove_siemens',\n",
    "        'aeg': 'stove_aeg',\n",
    "        'neff': 'stove_neff',\n",
    "        'gaggenau': 'stove_gaggenau',\n",
    "        'smeg': 'stove_smeg',\n",
    "        'whirlpool': 'stove_whirlpool',\n",
    "        'electrolux': 'stove_electrolux',\n",
    "        'zanussi': 'stove_zanussi',\n",
    "        'beko': 'stove_beko',\n",
    "        'ikea': 'stove_ikea',\n",
    "        'haier': 'stove_haier',\n",
    "        'panasonic': 'stove_panasonic',\n",
    "        'teka': 'stove_teka',\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_stove\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in set(stove_types_patterns.keys()).union(brand_column_names.values()):\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Lowercase mapping for brands\n",
    "    brand_keys_lower = {k.lower(): v for k, v in brand_column_names.items()}\n",
    "\n",
    "    # Stove detection terms\n",
    "    stove_terms_pattern = re.compile(\n",
    "        r\"\\b(stove|cooktop|herd|range|stovetop|cooktop)\\b\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Check if stove term is present\n",
    "        if any(stove_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_stove\"].at[idx] = True\n",
    "\n",
    "            # ✅ Check for types if stove term present\n",
    "            for amenity_lower in amenities_lower:\n",
    "                if stove_terms_pattern.search(amenity_lower):\n",
    "                    for col_name, type_pattern in stove_types_patterns.items():\n",
    "                        if re.search(type_pattern, amenity_lower):\n",
    "                            new_cols[col_name].at[idx] = True\n",
    "\n",
    "                    # ✅ Check for brands if stove term present\n",
    "                    for brand_key_lower, col_name in brand_keys_lower.items():\n",
    "                        if brand_key_lower in amenity_lower:\n",
    "                            new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "828daa01-c015-4e0f-a0cb-ad552343b077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:15.889260Z",
     "start_time": "2025-07-13T13:16:15.588907Z"
    }
   },
   "outputs": [],
   "source": [
    "df = create_stove_columns(df)\n",
    "\n",
    "def count_stove_features(df):\n",
    "    stove_columns = [col for col in df.columns if col.startswith(\"stove_\")]\n",
    "    stove_counts = df[stove_columns].sum().sort_values(ascending=False)\n",
    "    return stove_counts.reset_index().rename(columns={\"index\": \"stove_feature\", 0: \"count\"})\n",
    "\n",
    "def count_stoves_with_and_without_features(df):\n",
    "    stove_columns = [col for col in df.columns if col.startswith(\"stove_\") and col != \"has_stove\"]\n",
    "    has_feature = df[stove_columns].any(axis=1)\n",
    "    with_feature = ((df[\"has_stove\"]) & (has_feature)).sum()\n",
    "    without_feature = ((df[\"has_stove\"]) & (~has_feature)).sum()\n",
    "    return {\"with_feature\": int(with_feature), \"without_feature\": int(without_feature)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62402cc8-e128-464d-970f-0348cbf30c98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:15.947740Z",
     "start_time": "2025-07-13T13:16:15.940779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 90 | Displaying amenities and detected stove type(s) ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       amenities  has_stove  stove_induction\n",
      "90  [\"Drying rack for clothing\", \"Portable fans\", \"Dishes and silverware\", \"Garden view\", \"Bed linens\", \"Paid parking lot on premises \\u2013 1 space\", \"Cleaning available during stay\", \"Laundromat nearby\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Outdoor dining area\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Wifi\", \"Coffee\", \"Dishwasher\", \"Cleaning products\", \"Window guards\", \"Freezer\", \"Pets allowed\", \"Private patio or balcony\", \"Radiant heating\", \"Cooking basics\", \"Fire extinguisher\", \"First aid kit\", \"Essentials\", \"Coffee maker\", \"Hair dryer\", \"Extra pillows and blankets\", \"Carbon monoxide alarm\", \"Central heating\", \"Hot water kettle\", \"Dedicated workspace\", \"Kitchen\", \"Clothing storage: walk-in closet\", \"Outdoor furniture\", \"Single level home\", \"Iron\", \"Barbecue utensils\", \"Paid parking garage off premises\", \"Wine glasses\", \"Bikes\", \"Hot water\", \"Body soap\", \"Room-darkening shades\", \"Children\\u2019s books and toys\", \"Smoke alarm\", \"Sonstiges induction stove\", \"Baking sheet\", \"Host greets you\", \"Shared backyard \\u2013 Not fully fenced\", \"Indoor fireplace: pellet stove\", \"Private entrance\", \"Board games\", \"Oven\", \"Toaster\", \"Courtyard view\", \"Dining table\", \"Free washer \\u2013 In unit\", \"Portable heater\", \"TV with standard cable\", \"Microwave\"]       True             True\n"
     ]
    }
   ],
   "source": [
    "# Identify stove columns\n",
    "stove_columns = [col for col in df.columns if col.startswith(\"stove_\")]\n",
    "\n",
    "# Get indices where any stove type was detected\n",
    "indices_with_stove_type = df[df[stove_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 20\n",
    "index_to_check = indices_with_stove_type[test_index]\n",
    "\n",
    "# Filter columns with True for this index\n",
    "true_stove_columns = [col for col in stove_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for validation\n",
    "columns_to_display = [\"amenities\", \"has_stove\"] + true_stove_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected stove type(s) ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81b41f-6360-483b-b983-5831863b61bd",
   "metadata": {},
   "source": [
    "### Sound system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c780a6e-a9ef-41ed-b3db-85427e78d7a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:16.191448Z",
     "start_time": "2025-07-13T13:16:16.186084Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_amenities_at_index(df, index):\n",
    "    raw_string = df.loc[index, \"amenities\"]\n",
    "    amenities_list = json.loads(raw_string)\n",
    "    return amenities_list\n",
    "\n",
    "def create_sound_system_columns(df):\n",
    "    # ✅ Clean trade brands for sound systems (expandable)\n",
    "    brand_column_names = {\n",
    "        'bose': 'sound_bose',\n",
    "        'sonos': 'sound_sonos',\n",
    "        'jbl': 'sound_jbl',\n",
    "        'sony': 'sound_sony',\n",
    "        'marshall': 'sound_marshall',\n",
    "        'bang & olufsen': 'sound_bang_olufsen',\n",
    "        'b&o': 'sound_bang_olufsen',\n",
    "        'yamaha': 'sound_yamaha',\n",
    "        'samsung': 'sound_samsung',\n",
    "        'lg': 'sound_lg',\n",
    "        'philips': 'sound_philips',\n",
    "        'panasonic': 'sound_panasonic',\n",
    "        'teufel': 'sound_teufel',\n",
    "        'denon': 'sound_denon',\n",
    "        'pioneer': 'sound_pioneer',\n",
    "        'onkyo': 'sound_onkyo',\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_sound_system\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in set(brand_column_names.values()):\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Lowercase brand mapping\n",
    "    brand_keys_lower = {k.lower(): v for k, v in brand_column_names.items()}\n",
    "    sound_terms = [\"sound system\", \"stereo\", \"speaker\", \"speakers\", \"lautsprecher\", \"soundanlage\", \"hi-fi\", \"hifi\", \"soundbar\"]\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Set has_sound_system if any sound-related term found\n",
    "        if any(any(term in a for term in sound_terms) for a in amenities_lower):\n",
    "            new_cols[\"has_sound_system\"].at[idx] = True\n",
    "\n",
    "        # Set brand columns if sound term + brand in the same amenity\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if any(term in amenity_lower for term in sound_terms):\n",
    "                for brand_key_lower, col_name in brand_keys_lower.items():\n",
    "                    if brand_key_lower in amenity_lower:\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    # Add to df\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af2fee73-283e-460a-aa14-cf1b31e42014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:16.252845Z",
     "start_time": "2025-07-13T13:16:16.249820Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_sound_system_brands(df):\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"sound_\") and col != \"has_sound_system\"]\n",
    "    brand_counts = df[brand_columns].sum().sort_values(ascending=False)\n",
    "    return brand_counts.reset_index().rename(columns={\"index\": \"brand_column\", 0: \"count\"})\n",
    "\n",
    "def count_sound_systems_with_and_without_brand(df):\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"sound_\") and col != \"has_sound_system\"]\n",
    "    has_brand = df[brand_columns].any(axis=1)\n",
    "    with_brand = ((df[\"has_sound_system\"]) & (has_brand)).sum()\n",
    "    without_brand = ((df[\"has_sound_system\"]) & (~has_brand)).sum()\n",
    "    return {\"with_brand\": int(with_brand), \"without_brand\": int(without_brand)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a03a34eb-2adf-48e7-89ec-498484154812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:16.706006Z",
     "start_time": "2025-07-13T13:16:16.298717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_brand': 279, 'without_brand': 751}\n",
      "          brand_column  count\n",
      "0          sound_sonos    106\n",
      "1           sound_bose     45\n",
      "2         sound_teufel     20\n",
      "3         sound_yamaha     20\n",
      "4       sound_marshall     19\n",
      "5   sound_bang_olufsen     18\n",
      "6           sound_sony     15\n",
      "7            sound_jbl     11\n",
      "8             sound_lg      9\n",
      "9        sound_pioneer      7\n",
      "10       sound_samsung      7\n",
      "11       sound_philips      5\n",
      "12     sound_panasonic      4\n",
      "13         sound_onkyo      3\n",
      "14         sound_denon      3\n"
     ]
    }
   ],
   "source": [
    "df = create_sound_system_columns(df)\n",
    "\n",
    "# Get counts\n",
    "sound_brand_counts_df = count_sound_system_brands(df)\n",
    "sound_counts = count_sound_systems_with_and_without_brand(df)\n",
    "\n",
    "print(sound_counts)\n",
    "print(sound_brand_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02f8f512-53fa-4fc2-ab52-bd03701f114f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:16.761360Z",
     "start_time": "2025-07-13T13:16:16.755635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 270 | Displaying amenities and detected sound system brand(s) ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      amenities  has_sound_system  sound_onkyo\n",
      "270  [\"Dishes and silverware\", \"Bed linens\", \"Long term stays allowed\", \"Hangers\", \"AEG refrigerator\", \"Wifi\", \"Dishwasher\", \"Other electric stove\", \"Cleaning products\", \"Onkyo sound system\", \"Window guards\", \"Coffee maker: drip coffee maker\", \"Cooking basics\", \"Essentials\", \"Hair dryer\", \"Heating\", \"Clothing storage: closet and wardrobe\", \"Hot water kettle\", \"Elevator\", \"Kitchen\", \"Single level home\", \"Iron\", \"Wine glasses\", \"Free street parking\", \"Washer\", \"Body soap\", \"Hot water\", \"Room-darkening shades\", \"Private entrance\", \"Oven\", \"Toaster\", \"Dining table\", \"TV with standard cable\", \"Microwave\"]              True         True\n"
     ]
    }
   ],
   "source": [
    "# Identify sound system brand columns\n",
    "sound_columns = [col for col in df.columns if col.startswith(\"sound_\") and col != \"has_sound_system\"]\n",
    "\n",
    "# Get indices where any sound system brand was detected\n",
    "indices_with_sound_brand = df[df[sound_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 10\n",
    "index_to_check = indices_with_sound_brand[test_index]\n",
    "\n",
    "# Filter columns with True for this index\n",
    "true_sound_columns = [col for col in sound_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for validation\n",
    "columns_to_display = [\"amenities\", \"has_sound_system\"] + true_sound_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected sound system brand(s) ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18946535-4567-450e-aaa8-95b1caad8073",
   "metadata": {},
   "source": [
    "### Coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c0e981b-755c-4564-b7a3-a19403850814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:16.819516Z",
     "start_time": "2025-07-13T13:16:16.813877Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_coffee_maker_columns(df):\n",
    "    # Expanded detection patterns with regex-friendly variants\n",
    "    coffee_types_patterns = {\n",
    "        \"coffee_espresso\": r\"\\bespresso\\b\",\n",
    "        \"coffee_french_plus\": r\"\\bfrench press\\b\",\n",
    "        \"coffee_nespresso\": r\"\\bnespresso\\b\",\n",
    "        \"pour_over_coffee\": r\"\\bpour[- ]over( coffee)?\\b\",\n",
    "    }\n",
    "\n",
    "    new_cols = {\n",
    "        \"has_coffee_maker\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in coffee_types_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Terms for has_coffee_maker detection (expanded)\n",
    "    coffee_terms_pattern = re.compile(r\"\\b(?:coffee|kaffee|espresso|french press|nespresso|pour[- ]over(?: coffee)?)\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Precise has_coffee_maker detection\n",
    "        if any(coffee_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_coffee_maker\"].at[idx] = True\n",
    "\n",
    "        # ✅ Precise per-type detection\n",
    "        for amenity_lower in amenities_lower:\n",
    "            for col_name, pattern in coffee_types_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "118b1272-79b6-4cc5-82a6-91008da7830b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:16.878950Z",
     "start_time": "2025-07-13T13:16:16.875166Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_coffee_maker_types(df):\n",
    "    coffee_columns = [col for col in df.columns if col.startswith(\"coffee_\") or col == \"pour_over_coffee\"]\n",
    "    coffee_counts = df[coffee_columns].sum().sort_values(ascending=False)\n",
    "    return coffee_counts.reset_index().rename(columns={\"index\": \"coffee_type\", 0: \"count\"})\n",
    "\n",
    "def count_coffee_makers_with_and_without_types(df):\n",
    "    coffee_columns = [col for col in df.columns if col.startswith(\"coffee_\") or col == \"pour_over_coffee\"]\n",
    "    has_type = df[coffee_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_coffee_maker\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_coffee_maker\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5a87481-2881-448a-a2d5-30e739ac16fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:17.703643Z",
     "start_time": "2025-07-13T13:16:16.935821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 1857, 'without_type': 3870}\n",
      "          coffee_type  count\n",
      "0    coffee_nespresso    915\n",
      "1     coffee_espresso    505\n",
      "2  coffee_french_plus    386\n",
      "3    pour_over_coffee    369\n"
     ]
    }
   ],
   "source": [
    "df = create_coffee_maker_columns(df)\n",
    "\n",
    "# Get counts\n",
    "coffee_counts_df = count_coffee_maker_types(df)\n",
    "coffee_summary = count_coffee_makers_with_and_without_types(df)\n",
    "\n",
    "print(coffee_summary)\n",
    "print(coffee_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca8981d8-c7d6-4382-bb9d-c1d709f07977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:17.782337Z",
     "start_time": "2025-07-13T13:16:17.774406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 42 | Displaying amenities and detected coffee type(s) ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    amenities  has_coffee_maker  coffee_espresso  coffee_nespresso\n",
      "42  [\"Bathtub\", \"Drying rack for clothing\", \"Shared backyard \\u2013 Fully fenced\", \"Shower gel\", \"Dishes and silverware\", \"Bed linens\", \"Laundromat nearby\", \"Sound system with Bluetooth and aux\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Outdoor dining area\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Park view\", \"High chair\", \"Coffee\", \"Shampoo\", \"Dishwasher\", \"Children\\u2019s dinnerware\", \"Cleaning products\", \"Freezer\", \"Cooking basics\", \"Outlet covers\", \"Fire extinguisher\", \"First aid kit\", \"Essentials\", \"Blender\", \"Changing table\", \"Piano\", \"Hair dryer\", \"Coffee maker: drip coffee maker, espresso machine, Nespresso\", \"Carbon monoxide alarm\", \"Babysitter recommendations\", \"Central heating\", \"Hot water kettle\", \"Dedicated workspace\", \"Kitchen\", \"Pack \\u2019n play/Travel crib\", \"Outdoor furniture\", \"Fast wifi \\u2013 583 Mbps\", \"Iron\", \"Wine glasses\", \"Mosquito net\", \"Free street parking\", \"Hot water\", \"Body soap\", \"Room-darkening shades\", \"Children\\u2019s books and toys\", \"Smoke alarm\", \"Sonstiges induction stove\", \"Baking sheet\", \"Crib\", \"Host greets you\", \"Board games\", \"Oven\", \"Toaster\", \"Dining table\", \"Free washer \\u2013 In unit\", \"Private patio or balcony\", \"Exercise equipment\", \"Microwave\"]              True             True              True\n"
     ]
    }
   ],
   "source": [
    "# Identify coffee columns\n",
    "coffee_columns = [col for col in df.columns if col.startswith(\"coffee_\") or col == \"pour_over_coffee\"]\n",
    "\n",
    "# Get indices where any coffee type was detected\n",
    "indices_with_coffee_type = df[df[coffee_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index for inspection\n",
    "test_index = 4\n",
    "index_to_check = indices_with_coffee_type[test_index]\n",
    "\n",
    "# Filter columns with True for this index\n",
    "true_coffee_columns = [col for col in coffee_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for validation\n",
    "columns_to_display = [\"amenities\", \"has_coffee_maker\"] + true_coffee_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected coffee type(s) ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f115f-3685-437e-946b-4fce4849ba8d",
   "metadata": {},
   "source": [
    "### Excercise Equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7bfcff0-a58b-4b50-8e4f-0756abb7a04d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:17.879575Z",
     "start_time": "2025-07-13T13:16:17.875878Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_exercise_equipment_columns(df):\n",
    "    # ✅ Define patterns for equipment types\n",
    "    equipment_types_patterns = {\n",
    "        \"exercise_equipment_free_weights\": r\"\\b(dumbbells?|free weights?|kettlebells?)\\b\",\n",
    "        \"exercise_equipment_elliptical\": r\"\\belliptical\\b\",\n",
    "        \"exercise_equipment_stationary_bike\": r\"\\b(stationary bike|exercise bike|spinning bike)\\b\",\n",
    "        \"exercise_equipment_yoga_mat\": r\"\\b(yoga mat|yogamat)\\b\",\n",
    "        \"exercise_equipment_workout_bench\": r\"\\b(workout bench|weight bench|training bench)\\b\",\n",
    "        \"exercise_equipment_treadmill\": r\"\\btreadmill\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_exercise_equipment\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in equipment_types_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # General terms for 'has_exercise_equipment'\n",
    "    exercise_terms_pattern = re.compile(\n",
    "        r\"\\b(gym|fitness|exercise|workout|training|dumbbell|weights?|kettlebell|elliptical|bike|yoga|treadmill|rowing)\\b\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Set has_exercise_equipment if any relevant term detected\n",
    "        if any(exercise_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_exercise_equipment\"].at[idx] = True\n",
    "\n",
    "        # ✅ Set equipment type columns precisely\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if exercise_terms_pattern.search(amenity_lower):\n",
    "                for col_name, pattern in equipment_types_patterns.items():\n",
    "                    if re.search(pattern, amenity_lower):\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "386203e1-654b-474d-9227-5b41a4c33872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:17.953689Z",
     "start_time": "2025-07-13T13:16:17.949678Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_exercise_equipment_types(df):\n",
    "    equipment_columns = [col for col in df.columns if col.startswith(\"exercise_equipment_\")]\n",
    "    equipment_counts = df[equipment_columns].sum().sort_values(ascending=False)\n",
    "    return equipment_counts.reset_index().rename(columns={\"index\": \"equipment_type\", 0: \"count\"})\n",
    "\n",
    "def count_exercise_equipment_with_and_without_types(df):\n",
    "    equipment_columns = [col for col in df.columns if col.startswith(\"exercise_equipment_\") and col != \"has_exercise_equipment\"]\n",
    "    has_type = df[equipment_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_exercise_equipment\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_exercise_equipment\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7238cd1e-4ef8-4b5b-b088-80b8daa2c09a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:18.289416Z",
     "start_time": "2025-07-13T13:16:18.011984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 220, 'without_type': 403}\n",
      "                       equipment_type  count\n",
      "0         exercise_equipment_yoga_mat    147\n",
      "1     exercise_equipment_free_weights    126\n",
      "2       exercise_equipment_elliptical     26\n",
      "3  exercise_equipment_stationary_bike     21\n",
      "4    exercise_equipment_workout_bench     17\n",
      "5        exercise_equipment_treadmill     17\n"
     ]
    }
   ],
   "source": [
    "df = create_exercise_equipment_columns(df)\n",
    "\n",
    "# Get counts\n",
    "equipment_counts_df = count_exercise_equipment_types(df)\n",
    "equipment_summary = count_exercise_equipment_with_and_without_types(df)\n",
    "\n",
    "print(equipment_summary)\n",
    "print(equipment_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28131562-fed8-4c9a-b4ab-b2d00e3e9235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:18.408655Z",
     "start_time": "2025-07-13T13:16:18.400410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 485 | Displaying amenities and detected exercise equipment features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            amenities  has_exercise_equipment  exercise_equipment_yoga_mat\n",
      "485  [\"Free dryer \\u2013 In unit\", \"Drying rack for clothing\", \"Shared backyard \\u2013 Fully fenced\", \"Shower gel\", \"Dishes and silverware\", \"Nivea/Alterra body soap\", \"Bed linens\", \"Paid street parking off premises\", \"Laundromat nearby\", \"Long term stays allowed\", \"Outdoor dining area\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Sonstiges electric stove\", \"Exercise equipment: yoga mat\", \"Coffee\", \"Cleaning products\", \"Freezer\", \"Cooking basics\", \"Fire extinguisher\", \"Sound system\", \"First aid kit\", \"Housekeeping available from 4:00\\u202fPM to 8:00\\u202fPM, every day - available at extra cost\", \"Essentials\", \"Coffee maker\", \"Outdoor playground\", \"Hair dryer\", \"Extra pillows and blankets\", \"Carbon monoxide alarm\", \"Central heating\", \"Hot water kettle\", \"Elevator\", \"Self check-in\", \"Lockbox\", \"Kitchen\", \"Single level home\", \"Iron\", \"Wine glasses\", \"43 inch HDTV with standard cable\", \"Clothing storage: wardrobe\", \"Hot water\", \"Smoke alarm\", \"Room-darkening shades\", \"Baking sheet\", \"Frosch shampoo\", \"Private entrance\", \"Fast wifi \\u2013 189 Mbps\", \"Oven\", \"Toaster\", \"Courtyard view\", \"Dining table\", \"Free washer \\u2013 In unit\"]                    True                         True\n"
     ]
    }
   ],
   "source": [
    "# Identify exercise equipment columns\n",
    "equipment_columns = [col for col in df.columns if col.startswith(\"exercise_equipment_\")]\n",
    "\n",
    "# Get indices where any equipment detected\n",
    "indices_with_equipment = df[df[equipment_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 10\n",
    "index_to_check = indices_with_equipment[test_index]\n",
    "\n",
    "# Filter columns with True for this row\n",
    "true_equipment_columns = [col for col in equipment_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for QA\n",
    "columns_to_display = [\"amenities\", \"has_exercise_equipment\"] + true_equipment_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected exercise equipment features ===\")\n",
    "print(df_check.to_string(max_colwidth=2500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e6cf5-7077-4ae2-8dd7-16749dc82c55",
   "metadata": {},
   "source": [
    "### Game Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db938e53-cec1-4c43-984a-b0369e99488c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:18.518789Z",
     "start_time": "2025-07-13T13:16:18.513770Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_game_console_columns(df):\n",
    "    # ✅ Define regex patterns for each console\n",
    "    console_patterns = {\n",
    "        \"ps2\": r\"\\b(ps2|playstation 2)\\b\",\n",
    "        \"ps3\": r\"\\b(ps3|playstation 3)\\b\",\n",
    "        \"ps4\": r\"\\b(ps4|playstation 4)\\b\",\n",
    "        \"ps5\": r\"\\b(ps5|playstation 5)\\b\",\n",
    "        \"xbox360\": r\"\\b(xbox 360|xbox360)\\b\",\n",
    "        \"xboxone\": r\"\\b(xbox one|xboxone)\\b\",\n",
    "        \"nintendoswitch\": r\"\\b(nintendo switch|switch)\\b\",\n",
    "        \"wii\": r\"\\b(wii|nintendo wii)\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_game_console\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in console_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # General console detection pattern\n",
    "    console_terms_pattern = re.compile(\n",
    "        r\"\\b(playstation|ps[2-5]|xbox|nintendo|switch|wii|game console|gaming console)\\b\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Set has_game_console if general term detected\n",
    "        if any(console_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_game_console\"].at[idx] = True\n",
    "\n",
    "        # ✅ Set individual console columns if detected\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if console_terms_pattern.search(amenity_lower):\n",
    "                for col_name, pattern in console_patterns.items():\n",
    "                    if re.search(pattern, amenity_lower):\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8bc972f-aff8-4719-abe6-880449c9781e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:18.589339Z",
     "start_time": "2025-07-13T13:16:18.586385Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_game_console_types(df):\n",
    "    console_columns = [\"ps2\", \"ps3\", \"ps4\", \"ps5\", \"xbox360\", \"xboxone\", \"nintendoswitch\", \"wii\"]\n",
    "    console_counts = df[console_columns].sum().sort_values(ascending=False)\n",
    "    return console_counts.reset_index().rename(columns={\"index\": \"console_type\", 0: \"count\"})\n",
    "\n",
    "def count_game_consoles_with_and_without_type(df):\n",
    "    console_columns = [\"ps2\", \"ps3\", \"ps4\", \"ps5\", \"xbox360\", \"xboxone\", \"nintendoswitch\", \"wii\"]\n",
    "    has_type = df[console_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_game_console\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_game_console\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72c8e33a-423f-43a3-a07f-e9d019ba9c31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:19.001465Z",
     "start_time": "2025-07-13T13:16:18.638010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 88, 'without_type': 81}\n",
      "     console_type  count\n",
      "0             ps4     35\n",
      "1  nintendoswitch     21\n",
      "2             ps3     11\n",
      "3             ps5     11\n",
      "4             wii     11\n",
      "5         xboxone      7\n",
      "6         xbox360      3\n",
      "7             ps2      2\n"
     ]
    }
   ],
   "source": [
    "df = create_game_console_columns(df)\n",
    "\n",
    "# Get counts\n",
    "console_counts_df = count_game_console_types(df)\n",
    "console_summary = count_game_consoles_with_and_without_type(df)\n",
    "\n",
    "print(console_summary)\n",
    "print(console_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c33a3a6e-a08b-4170-9473-3a16e370be40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:19.105470Z",
     "start_time": "2025-07-13T13:16:19.085808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 11587 | Displaying amenities and detected game console features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   amenities  has_game_console   ps3\n",
      "11587  [\"Bathtub\", \"Drying rack for clothing\", \"Children's playroom\", \"Children\\u2019s books and toys for ages 2-5 years old and 5-10 years old\", \"Dishes and silverware\", \"Bed linens\", \"Pack \\u2019n play/Travel crib - always at the listing\", \"Laundromat nearby\", \"Luggage dropoff allowed\", \"Indoor fireplace: wood-burning\", \"Outdoor dining area\", \"Long term stays allowed\", \"Books and reading material\", \"Hangers\", \"HDTV\", \"Wifi\", \"Refrigerator\", \"Coffee\", \"Dishwasher\", \"Other electric stove\", \"Cleaning products\", \"Freezer\", \"Pets allowed\", \"Private backyard \\u2013 Fully fenced\", \"Cooking basics\", \"Fire extinguisher\", \"Essentials\", \"Coffee maker: pour-over coffee\", \"Piano\", \"Hair dryer\", \"Hot water kettle\", \"Central heating\", \"Waterfront\", \"Self check-in\", \"Batting cage\", \"Game console: PS3\", \"Dedicated workspace\", \"Kitchen\", \"Lockbox\", \"Iron\", \"Barbecue utensils\", \"Free washer\", \"Wine glasses\", \"Free street parking\", \"Clothing storage: wardrobe and dresser\", \"Changing table - always at the listing\", \"Hot water\", \"Smoke alarm\", \"Room-darkening shades\", \"Baking sheet\", \"Rice maker\", \"Single oven\", \"Free parking on premises\", \"Crib\", \"Private entrance\", \"Board games\", \"Dining table\", \"Private patio or balcony\", \"Fireplace guards\"]              True  True\n"
     ]
    }
   ],
   "source": [
    "# Identify console columns\n",
    "console_columns = [\"ps2\", \"ps3\", \"ps4\", \"ps5\", \"xbox360\", \"xboxone\", \"nintendoswitch\", \"wii\"]\n",
    "\n",
    "# Get indices where any console detected\n",
    "indices_with_console = df[df[console_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 70\n",
    "index_to_check = indices_with_console[test_index]\n",
    "\n",
    "# Columns with True for this row\n",
    "true_console_columns = [col for col in console_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for QA\n",
    "columns_to_display = [\"amenities\", \"has_game_console\"] + true_console_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected game console features ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da67d4-cfde-4157-9629-8b3c4cb7d22a",
   "metadata": {},
   "source": [
    "### TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13b94e12-23e3-4084-98f1-6a8e42ced49e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:19.223278Z",
     "start_time": "2025-07-13T13:16:19.218790Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def create_tv_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_tv\": pd.Series(False, index=df.index),\n",
    "        \"tv_size_inch\": pd.Series(None, index=df.index, dtype=float)\n",
    "    }\n",
    "\n",
    "    # TV detection pattern (detects tv, hdtv, smart tv, etc.)\n",
    "    tv_terms_pattern = re.compile(\n",
    "        r\"\\b(tv|television|smart tv|hdtv)\\b\"\n",
    "    )\n",
    "\n",
    "    # Pattern to extract TV size in inches\n",
    "    tv_size_pattern = re.compile(\n",
    "        r\"(\\d{2,3}(?:[.,]\\d+)?)\\s*(?:\\\"|inch|in|”)\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        found_tv = False\n",
    "        sizes = []\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            # Check if TV is mentioned\n",
    "            if tv_terms_pattern.search(amenity):\n",
    "                found_tv = True\n",
    "\n",
    "                # Attempt to extract size\n",
    "                size_match = tv_size_pattern.search(amenity)\n",
    "                if size_match:\n",
    "                    size_str = size_match.group(1).replace(\",\", \".\")\n",
    "                    try:\n",
    "                        size_float = float(size_str)\n",
    "                        sizes.append(size_float)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "        if found_tv:\n",
    "            new_cols[\"has_tv\"].at[idx] = True\n",
    "\n",
    "            # If multiple sizes are found, take the largest (most likely the primary TV)\n",
    "            if sizes:\n",
    "                new_cols[\"tv_size_inch\"].at[idx] = max(sizes)\n",
    "\n",
    "    # Add to df\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7f5fa44-514b-4d27-8453-d57700e408cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:20.238184Z",
     "start_time": "2025-07-13T13:16:19.393390Z"
    }
   },
   "outputs": [],
   "source": [
    "df = create_tv_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46e130b7-f105-4a78-a0e9-97cf12d2d2c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:20.377341Z",
     "start_time": "2025-07-13T13:16:20.369736Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_tv_summary(df):\n",
    "    has_tv = df[\"has_tv\"] == True\n",
    "    has_size = df[\"tv_size_inch\"].notna()\n",
    "\n",
    "    with_size = (has_tv & has_size).sum()\n",
    "    without_size = (has_tv & ~has_size).sum()\n",
    "    total_tv = has_tv.sum()\n",
    "\n",
    "    return {\n",
    "        \"total_tv\": int(total_tv),\n",
    "        \"with_size\": int(with_size),\n",
    "        \"without_size\": int(without_size)\n",
    "    }\n",
    "\n",
    "def count_tv_size_distribution(df, bins=None):\n",
    "    \"\"\"\n",
    "    Returns a distribution of TV sizes (using bins if provided).\n",
    "    \"\"\"\n",
    "    tv_sizes = df.loc[df[\"tv_size_inch\"].notna(), \"tv_size_inch\"]\n",
    "    if bins:\n",
    "        return pd.cut(tv_sizes, bins=bins).value_counts().sort_index()\n",
    "    else:\n",
    "        return tv_sizes.value_counts().sort_index()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15f36512-d0eb-477b-9498-518d35e6ed4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:20.492756Z",
     "start_time": "2025-07-13T13:16:20.480159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_tv': 6085, 'with_size': 825, 'without_size': 5260}\n",
      "tv_size_inch\n",
      "16.0       1\n",
      "23.0       2\n",
      "24.0       7\n",
      "25.0       1\n",
      "26.0       4\n",
      "27.0       2\n",
      "28.0       4\n",
      "30.0      10\n",
      "31.0       3\n",
      "32.0     106\n",
      "33.0       2\n",
      "34.0       5\n",
      "35.0      10\n",
      "37.0       2\n",
      "38.0       2\n",
      "39.0       4\n",
      "40.0      70\n",
      "41.0       5\n",
      "42.0      58\n",
      "43.0     121\n",
      "44.0       2\n",
      "45.0      11\n",
      "46.0      11\n",
      "47.0       6\n",
      "48.0      15\n",
      "49.0      12\n",
      "50.0      72\n",
      "52.0       7\n",
      "53.0       1\n",
      "54.0       3\n",
      "55.0     125\n",
      "56.0       2\n",
      "58.0       5\n",
      "60.0      14\n",
      "65.0      66\n",
      "70.0       8\n",
      "74.0       1\n",
      "75.0      12\n",
      "77.0       2\n",
      "80.0       3\n",
      "81.0       1\n",
      "82.0       1\n",
      "85.0       4\n",
      "86.0       1\n",
      "98.0       1\n",
      "100.0      2\n",
      "108.0      8\n",
      "110.0      2\n",
      "120.0      2\n",
      "140.0      1\n",
      "150.0      2\n",
      "164.0      1\n",
      "300.0      1\n",
      "400.0      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get TV counts summary\n",
    "tv_summary = count_tv_summary(df)\n",
    "\n",
    "# Get TV size distribution (optional)\n",
    "tv_size_distribution = count_tv_size_distribution(df)\n",
    "\n",
    "# Display results\n",
    "print(tv_summary)\n",
    "print(tv_size_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9bdf2c6-7c83-4ab2-92bc-930ebf910748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:20.671588Z",
     "start_time": "2025-07-13T13:16:20.663639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 88 | Displaying amenities and detected TV features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           amenities  has_tv  tv_size_inch\n",
      "88  [\"Dryer\", \"Dishes and silverware\", \"Bed linens\", \"Outdoor dining area\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Wifi\", \"Dishwasher\", \"Cleaning products\", \"Freezer\", \"Beach access \\u2013 Beachfront\", \"Electric stove\", \"Cooking basics\", \"Crib - available upon request\", \"Essentials\", \"Coffee maker\", \"Hair dryer\", \"Heating\", \"Hot water kettle\", \"Kitchen\", \"40 inch HDTV with Amazon Prime Video, Apple TV, Disney+, Netflix\", \"Iron\", \"Wine glasses\", \"Free street parking\", \"Washer\", \"Smoke alarm\", \"Body soap\", \"Room-darkening shades\", \"Hot water\", \"Host greets you\", \"Private entrance\", \"Ethernet connection\", \"Oven\", \"Toaster\", \"Dining table\", \"Microwave\"]    True          40.0\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows with TV\n",
    "indices_with_tv = df[df[\"tv_size_inch\"].notna()].index\n",
    "\n",
    "# Pick the nth row to inspect\n",
    "test_index = 9\n",
    "if test_index < len(indices_with_tv):\n",
    "    index_to_check = indices_with_tv[test_index]\n",
    "    df_check = df.loc[[index_to_check], [\"amenities\", \"has_tv\", \"tv_size_inch\"]]\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected TV features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_tv)} rows with has_tv == True; test_index {test_index} is out of range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b64358-2bb8-40af-9edc-515630912023",
   "metadata": {},
   "source": [
    "### Streaming Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a1d98e8-62d0-463d-bacf-1184ec35b3a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:20.803587Z",
     "start_time": "2025-07-13T13:16:20.795254Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_streaming_provider_columns(df):\n",
    "    # Streaming services detection patterns\n",
    "    streaming_patterns = {\n",
    "        \"streaming_netflix\": r\"\\b(netflix)\\b\",\n",
    "        \"streaming_amazon_prime_video\": r\"\\b(amazon prime video|prime video|amazon prime)\\b\",\n",
    "        \"streaming_apple_tv\": r\"\\b(apple tv|appletv)\\b\",\n",
    "        \"streaming_disney_plus\": r\"(disney\\+|disney plus|disney\\s*\\+)\"\n",
    "\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_streaming_provider\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in streaming_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # General detection pattern for has_streaming_provider\n",
    "    streaming_terms_pattern = re.compile(\n",
    "    r\"(netflix|amazon prime video|prime video|amazon prime|apple tv|appletv|disney\\+|disney plus|disney\\s*\\+)\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Flag has_streaming_provider if any relevant term detected\n",
    "        if any(streaming_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_streaming_provider\"].at[idx] = True\n",
    "\n",
    "        # Flag specific streaming providers\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if streaming_terms_pattern.search(amenity_lower):\n",
    "                for col_name, pattern in streaming_patterns.items():\n",
    "                    if re.search(pattern, amenity_lower):\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9a65f01-47fd-44a6-af66-424ae220f4b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:20.901528Z",
     "start_time": "2025-07-13T13:16:20.896635Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_streaming_provider_types(df):\n",
    "    streaming_columns = [col for col in df.columns if col.startswith(\"streaming_\")]\n",
    "    streaming_counts = df[streaming_columns].sum().sort_values(ascending=False)\n",
    "    return streaming_counts.reset_index().rename(columns={\"index\": \"streaming_provider\", 0: \"count\"})\n",
    "\n",
    "def count_streaming_providers_with_and_without_types(df):\n",
    "    streaming_columns = [col for col in df.columns if col.startswith(\"streaming_\") and col != \"has_streaming_provider\"]\n",
    "    has_type = df[streaming_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_streaming_provider\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_streaming_provider\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f195edd-1ddf-4dee-a0be-0ab6e7e1526d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:21.253686Z",
     "start_time": "2025-07-13T13:16:20.985155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 520, 'without_type': 0}\n",
      "             streaming_provider  count\n",
      "0             streaming_netflix    454\n",
      "1  streaming_amazon_prime_video    252\n",
      "2         streaming_disney_plus     97\n",
      "3            streaming_apple_tv     93\n"
     ]
    }
   ],
   "source": [
    "df = create_streaming_provider_columns(df)\n",
    "\n",
    "# Get counts\n",
    "streaming_counts_df = count_streaming_provider_types(df)\n",
    "streaming_summary = count_streaming_providers_with_and_without_types(df)\n",
    "\n",
    "print(streaming_summary)\n",
    "print(streaming_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f1dd843-c706-4769-ad97-4d7964fdefef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:21.323475Z",
     "start_time": "2025-07-13T13:16:21.317303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 26 | Displaying amenities and detected streaming providers ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             amenities  has_streaming_provider  streaming_netflix\n",
      "26  [\"Bathtub\", \"Drying rack for clothing\", \"Safe\", \"Portable fans\", \"Shared backyard \\u2013 Fully fenced\", \"Shower gel\", \"Dishes and silverware\", \"Bed linens\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Fast wifi \\u2013 321 Mbps\", \"Coffee\", \"Shampoo\", \"Dishwasher\", \"Cleaning products\", \"Freezer\", \"Coffee maker: Nespresso\", \"Electric stove\", \"Conditioner\", \"Cooking basics\", \"Outlet covers\", \"Fire extinguisher\", \"First aid kit\", \"Essentials\", \"Hair dryer\", \"Extra pillows and blankets\", \"Carbon monoxide alarm\", \"Central heating\", \"Hot water kettle\", \"Dedicated workspace\", \"Kitchen\", \"Single level home\", \"Iron\", \"Wine glasses\", \"Free street parking\", \"Hot water\", \"Body soap\", \"Smoke alarm\", \"Baking sheet\", \"Host greets you\", \"Clothing storage: dresser\", \"Board games\", \"Oven\", \"Toaster\", \"Dining table\", \"26 inch HDTV with Netflix, premium cable\", \"Free washer \\u2013 In unit\", \"Microwave\"]                    True               True\n"
     ]
    }
   ],
   "source": [
    "# Identify streaming columns\n",
    "streaming_columns = [col for col in df.columns if col.startswith(\"streaming_\")]\n",
    "\n",
    "# Get indices where any streaming service is detected\n",
    "indices_with_streaming = df[df[\"has_streaming_provider\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 3\n",
    "if test_index < len(indices_with_streaming):\n",
    "    index_to_check = indices_with_streaming[test_index]\n",
    "    true_streaming_columns = [col for col in streaming_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\", \"has_streaming_provider\"] + true_streaming_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "    \n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected streaming providers ===\")\n",
    "    print(df_check.to_string(max_colwidth=2000))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_streaming)} rows with has_streaming_provider == True; test_index {test_index} is out of range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284519a-3d92-4335-864d-83ba0e23d01e",
   "metadata": {},
   "source": [
    "### Wardrobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "085603dc-bac9-4514-a1e9-ee3fe6eb4e96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:21.395231Z",
     "start_time": "2025-07-13T13:16:21.389323Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_clothing_storage_columns(df):\n",
    "    # Clothing storage patterns\n",
    "    clothing_patterns = {\n",
    "        \"clothing_storage_closet\": r\"\\bcloset\\b\",\n",
    "        \"clothing_storage_wardrobe\": r\"\\bwardrobe\\b\",\n",
    "        \"clothing_storage_walk_in\": r\"\\bwalk[- ]?in\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_clothing_storage\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in clothing_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # General detection pattern for has_clothing_storage\n",
    "    storage_terms_pattern = re.compile(\n",
    "        r\"\\b(clothing storage|closet|wardrobe)\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Flag has_clothing_storage if any relevant term detected\n",
    "        if any(storage_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_clothing_storage\"].at[idx] = True\n",
    "\n",
    "        # Flag specific types\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if storage_terms_pattern.search(amenity_lower):\n",
    "                for col_name, pattern in clothing_patterns.items():\n",
    "                    if re.search(pattern, amenity_lower):\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10bbfd46-cbf9-4b16-9055-bcaf8471e440",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:21.466205Z",
     "start_time": "2025-07-13T13:16:21.459366Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_clothing_storage_types(df):\n",
    "    clothing_columns = [col for col in df.columns if col.startswith(\"clothing_storage_\")]\n",
    "    clothing_counts = df[clothing_columns].sum().sort_values(ascending=False)\n",
    "    return clothing_counts.reset_index().rename(columns={\"index\": \"clothing_storage_type\", 0: \"count\"})\n",
    "\n",
    "def count_clothing_storage_with_and_without_types(df):\n",
    "    clothing_columns = [col for col in df.columns if col.startswith(\"clothing_storage_\") and col != \"has_clothing_storage\"]\n",
    "    has_type = df[clothing_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_clothing_storage\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_clothing_storage\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d84903ab-ebcc-40ee-881f-d1ad9f191e59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:21.906388Z",
     "start_time": "2025-07-13T13:16:21.572459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 2293, 'without_type': 1921}\n",
      "       clothing_storage_type  count\n",
      "0  clothing_storage_wardrobe   1672\n",
      "1    clothing_storage_closet    836\n",
      "2   clothing_storage_walk_in    117\n"
     ]
    }
   ],
   "source": [
    "df = create_clothing_storage_columns(df)\n",
    "\n",
    "# Get counts\n",
    "clothing_counts_df = count_clothing_storage_types(df)\n",
    "clothing_summary = count_clothing_storage_with_and_without_types(df)\n",
    "\n",
    "print(clothing_summary)\n",
    "print(clothing_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd771a68-3db5-4f85-8ba7-ef11ea9db1fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:22.004302Z",
     "start_time": "2025-07-13T13:16:21.996325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 23 | Displaying amenities and detected clothing storage features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           amenities  has_clothing_storage  clothing_storage_wardrobe\n",
      "23  [\"Bathtub\", \"Free dryer \\u2013 In unit\", \"Drying rack for clothing\", \"Dishes and silverware\", \"Bed linens\", \"Long term stays allowed\", \"Refrigerator\", \"Hangers\", \"Wifi\", \"High chair\", \"Cooking basics\", \"Essentials\", \"Coffee maker\", \"Hair dryer\", \"Extra pillows and blankets\", \"Smart lock\", \"Central heating\", \"Self check-in\", \"Kitchen\", \"Single level home\", \"Iron\", \"Paid parking off premises\", \"Stove\", \"Clothing storage: wardrobe\", \"Smoke alarm\", \"Hot water\", \"Oven\", \"Free washer \\u2013 In unit\", \"Microwave\"]                  True                       True\n"
     ]
    }
   ],
   "source": [
    "# Identify clothing storage columns\n",
    "clothing_columns = [col for col in df.columns if col.startswith(\"clothing_storage_\")]\n",
    "\n",
    "# Get indices where clothing storage detected\n",
    "indices_with_clothing = df[df[\"has_clothing_storage\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 4\n",
    "if test_index < len(indices_with_clothing):\n",
    "    index_to_check = indices_with_clothing[test_index]\n",
    "    true_clothing_columns = [col for col in clothing_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\", \"has_clothing_storage\"] + true_clothing_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "    \n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected clothing storage features ===\")\n",
    "    print(df_check.to_string(max_colwidth=2000))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_clothing)} rows with has_clothing_storage == True; test_index {test_index} is out of range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54839c4-d5a5-4b2b-b203-be7a552bf6df",
   "metadata": {},
   "source": [
    "### Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0244f54-59e8-4e95-8dfe-41149a86e285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:22.068642Z",
     "start_time": "2025-07-13T13:16:22.063583Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_parking_columns(df):\n",
    "    # Parking patterns\n",
    "    parking_patterns = {\n",
    "        \"parking_free_carport\": r\"\\bfree carport\\b\",\n",
    "        \"parking_free_driveway\": r\"\\bfree driveway parking\\b\",\n",
    "        \"parking_free_garage\": r\"\\bfree parking garage\\b\",\n",
    "        \"parking_free_residential_garage\": r\"\\bfree residential garage\\b\",\n",
    "        \"parking_free_street\": r\"\\bfree street parking\\b\",\n",
    "        \"parking_paid_garage\": r\"\\bpaid parking garage\\b\",\n",
    "        \"parking_paid_lot\": r\"\\bpaid parking lot\\b\",\n",
    "        \"parking_paid\": r\"\\bpaid parking\\b\",\n",
    "        \"parking_paid_street\": r\"\\bpaid street parking\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_parking\": pd.Series(False, index=df.index),\n",
    "        \"parking_on_premises\": pd.Series(False, index=df.index),\n",
    "        \"parking_off_premises\": pd.Series(False, index=df.index),\n",
    "    }\n",
    "    for col in parking_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # General parking detection\n",
    "    parking_terms_pattern = re.compile(\n",
    "        r\"\\b(parking|carport|driveway|garage)\\b\"\n",
    "    )\n",
    "    on_premises_pattern = re.compile(r\"\\bon[- ]premises\\b\")\n",
    "    off_premises_pattern = re.compile(r\"\\boff[- ]premises\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Check if any parking mention exists\n",
    "        if any(parking_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_parking\"].at[idx] = True\n",
    "\n",
    "        # Check for on-premises / off-premises\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if on_premises_pattern.search(amenity_lower):\n",
    "                new_cols[\"parking_on_premises\"].at[idx] = True\n",
    "            if off_premises_pattern.search(amenity_lower):\n",
    "                new_cols[\"parking_off_premises\"].at[idx] = True\n",
    "\n",
    "            # Flag detailed parking types\n",
    "            for col_name, pattern in parking_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    # Add columns to df\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "836ee19e-6800-436a-9263-75b82f848432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:22.145269Z",
     "start_time": "2025-07-13T13:16:22.141173Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_parking_types(df):\n",
    "    parking_columns = [col for col in df.columns if col.startswith(\"parking_\")]\n",
    "    parking_counts = df[parking_columns].sum().sort_values(ascending=False)\n",
    "    return parking_counts.reset_index().rename(columns={\"index\": \"parking_type\", 0: \"count\"})\n",
    "\n",
    "def count_parking_with_and_without_types(df):\n",
    "    parking_columns = [col for col in df.columns if col.startswith(\"parking_\") and col != \"has_parking\"]\n",
    "    has_type = df[parking_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_parking\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_parking\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "737ff259-614f-4a4f-aeac-d1644b563ac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:24.072563Z",
     "start_time": "2025-07-13T13:16:22.242732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 5234, 'without_type': 0}\n",
      "                       parking_type  count\n",
      "0               parking_free_street   2391\n",
      "1               parking_on_premises   2212\n",
      "2              parking_off_premises   1908\n",
      "3                      parking_paid   1860\n",
      "4               parking_paid_street    901\n",
      "5                  parking_paid_lot    215\n",
      "6               parking_paid_garage    207\n",
      "7             parking_free_driveway     50\n",
      "8   parking_free_residential_garage     27\n",
      "9               parking_free_garage     10\n",
      "10             parking_free_carport      9\n"
     ]
    }
   ],
   "source": [
    "df = create_parking_columns(df)\n",
    "\n",
    "# Get counts\n",
    "parking_counts_df = count_parking_types(df)\n",
    "parking_summary = count_parking_with_and_without_types(df)\n",
    "\n",
    "print(parking_summary)\n",
    "print(parking_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ab13bae-c836-4849-8958-3027d9ba26b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:24.188878Z",
     "start_time": "2025-07-13T13:16:24.172263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 28 | Displaying amenities and detected parking features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            amenities  has_parking  parking_on_premises  parking_off_premises  parking_paid\n",
      "28  [\"Noise decibel monitors on property\", \"Dishes and silverware\", \"City skyline view\", \"Bed linens\", \"Laundromat nearby\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Refrigerator\", \"Hangers\", \"Wifi\", \"High chair\", \"Shampoo\", \"Dishwasher\", \"Paid parking on premises\", \"Pets allowed\", \"Cooking basics\", \"Fire extinguisher\", \"Sound system\", \"Essentials\", \"Hair dryer\", \"Extra pillows and blankets\", \"Heating\", \"Hot water kettle\", \"Self check-in\", \"Dedicated workspace\", \"Lockbox\", \"Kitchen\", \"Pack \\u2019n play/Travel crib\", \"Single level home\", \"Iron\", \"TV with standard cable, Netflix\", \"Baby bath\", \"Paid parking off premises\", \"Washer\", \"Pocket wifi\", \"Stove\", \"Coffee maker: espresso machine\", \"Body soap\", \"Smoke alarm\", \"Room-darkening shades\", \"Children\\u2019s books and toys\", \"Crib\", \"Private entrance\", \"Ethernet connection\", \"Oven\", \"Courtyard view\", \"Microwave\"]         True                 True                  True          True\n"
     ]
    }
   ],
   "source": [
    "# Identify parking columns\n",
    "parking_columns = [col for col in df.columns if col.startswith(\"parking_\")]\n",
    "\n",
    "# Get indices where parking detected\n",
    "indices_with_parking = df[df[\"has_parking\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 16\n",
    "if test_index < len(indices_with_parking):\n",
    "    index_to_check = indices_with_parking[test_index]\n",
    "    true_parking_columns = [col for col in parking_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\", \"has_parking\"] + true_parking_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "    \n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected parking features ===\")\n",
    "    print(df_check.to_string(max_colwidth=2000))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_parking)} rows with has_parking == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ccb63b-f566-4a8e-a101-4b5f265d585a",
   "metadata": {},
   "source": [
    "### Outdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f80a6002-c461-4368-9ef9-86fbc03e29a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:24.323685Z",
     "start_time": "2025-07-13T13:16:24.296840Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_outdoor_columns(df):\n",
    "    # Explicit patterns for detection\n",
    "    outdoor_patterns = {\n",
    "        \"outdoor_dining_area\": r\"outdoor dining area\",\n",
    "        \"outdoor_furniture\": r\"outdoor furniture\",\n",
    "        \"outdoor_kitchen\": r\"outdoor kitchen\",\n",
    "        \"outdoor_playground\": r\"outdoor playground\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_outdoor\": pd.Series(False, index=df.index),\n",
    "        \"outdoor_pool_shared\": pd.Series(False, index=df.index),\n",
    "        \"outdoor_pool_private\": pd.Series(False, index=df.index),\n",
    "    }\n",
    "    for col in outdoor_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Pool patterns\n",
    "    shared_pool_pattern = re.compile(r\"\\b(shared outdoor pool|community pool|shared pool)\\b\")\n",
    "    private_pool_pattern = re.compile(r\"\\b(outdoor pool|private outdoor pool|swimming pool)\\b\")  # Keep \"pool\" last for broad catch\n",
    "\n",
    "    # Phrases for has_outdoor detection\n",
    "    outdoor_terms = [\n",
    "        \"outdoor dining area\",\n",
    "        \"outdoor furniture\",\n",
    "        \"outdoor kitchen\",\n",
    "        \"outdoor playground\",\n",
    "        \"outdoor pool\",\n",
    "        \"shared outdoor pool\",\n",
    "        \"private outdoor pool\",\n",
    "        \"community pool\",\n",
    "        \"shared pool\",\n",
    "    ]\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Set has_outdoor only if one of the clear outdoor terms is present\n",
    "        if any(any(term in a for term in outdoor_terms) for a in amenities_lower):\n",
    "            new_cols[\"has_outdoor\"].at[idx] = True\n",
    "\n",
    "        # ✅ Check shared/private pools\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if shared_pool_pattern.search(amenity_lower):\n",
    "                new_cols[\"outdoor_pool_shared\"].at[idx] = True\n",
    "            elif private_pool_pattern.search(amenity_lower):\n",
    "                # Only mark as private if not marked as shared\n",
    "                if not shared_pool_pattern.search(amenity_lower):\n",
    "                    new_cols[\"outdoor_pool_private\"].at[idx] = True\n",
    "\n",
    "            # ✅ Check specific features\n",
    "            for col_name, pattern in outdoor_patterns.items():\n",
    "                if pattern in amenity_lower:\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f500e13b-30b4-4a4d-89a5-b31f88dcb729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:25.119981Z",
     "start_time": "2025-07-13T13:16:25.114461Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_outdoor_types(df):\n",
    "    outdoor_columns = [col for col in df.columns if col.startswith(\"outdoor_\")]\n",
    "    outdoor_counts = df[outdoor_columns].sum().sort_values(ascending=False)\n",
    "    return outdoor_counts.reset_index().rename(columns={\"index\": \"outdoor_type\", 0: \"count\"})\n",
    "\n",
    "def count_outdoor_with_and_without_types(df):\n",
    "    outdoor_columns = [col for col in df.columns if col.startswith(\"outdoor_\") and col != \"has_outdoor\"]\n",
    "    has_type = df[outdoor_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_outdoor\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_outdoor\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8e19096-7da1-43eb-afa3-44542eb16042",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:25.799324Z",
     "start_time": "2025-07-13T13:16:25.182404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 2097, 'without_type': 0}\n",
      "           outdoor_type  count\n",
      "0   outdoor_dining_area   1536\n",
      "1     outdoor_furniture   1315\n",
      "2    outdoor_playground    444\n",
      "3       outdoor_kitchen     32\n",
      "4   outdoor_pool_shared     22\n",
      "5  outdoor_pool_private     11\n"
     ]
    }
   ],
   "source": [
    "df = create_outdoor_columns(df)\n",
    "\n",
    "# Get counts\n",
    "outdoor_counts_df = count_outdoor_types(df)\n",
    "outdoor_summary = count_outdoor_with_and_without_types(df)\n",
    "\n",
    "print(outdoor_summary)\n",
    "print(outdoor_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57ce484d-9985-4a83-9a8e-8d934a0b0849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:25.878069Z",
     "start_time": "2025-07-13T13:16:25.869246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 5875 | Displaying amenities and detected outdoor features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               amenities  has_outdoor\n",
      "5875  [\"Bathtub\", \"Drying rack for clothing\", \"Children's playroom\", \"Dishes and silverware\", \"Garden view\", \"Bed linens\", \"Children\\u2019s bikes\", \"Indoor fireplace: wood-burning\", \"Ping pong table\", \"Outdoor dining area\", \"Hangers\", \"Dishwasher\", \"Children\\u2019s dinnerware\", \"Game console: PS4\", \"Fast wifi \\u2013 147 Mbps\", \"Freezer\", \"Coffee maker: Nespresso\", \"Hammock\", \"Private backyard \\u2013 Fully fenced\", \"Bidet\", \"Cooking basics\", \"Fire extinguisher\", \"Essentials\", \"Standalone high chair - available upon request\", \"Pack \\u2019n play/Travel crib - available upon request\", \"Blender\", \"Outdoor playground\", \"Piano\", \"Free dryer \\u2013 In building\", \"Hair dryer\", \"Carbon monoxide alarm\", \"Central heating\", \"Children\\u2019s books and toys for ages 5-10 years old and 10+ years old\", \"Exterior security cameras on property\", \"Hot water kettle\", \"Self check-in\", \"Harman-Kardon sound system with aux\", \"Lockbox\", \"Kitchen\", \"Outdoor furniture\", \"55 inch HDTV with Amazon Prime Video, Netflix, DVD player\", \"Private hot tub - available seasonally, open 24 hours\", \"Iron\", \"Private outdoor pool - available seasonally, open specific hours, pool cover\", \"Barbecue utensils\", \"Wine glasses\", \"Free street parking\", \"Outdoor shower\", \"Siemens refrigerator\", \"Private BBQ grill: gas\", \"Free washer \\u2013 In building\", \"Clothing storage: wardrobe\", \"Hot water\", \"Smoke alarm\", \"Room-darkening shades\", \"Baking sheet\", \"Siemens stainless steel single oven\", \"Private entrance\", \"Board games\", \"Free driveway parking on premises \\u2013 1 space\", \"Ethernet connection\", \"Dining table\", \"Induction stove\", \"Toaster\", \"Private patio or balcony\", \"Pool view\", \"Microwave\"]         True\n"
     ]
    }
   ],
   "source": [
    "# Identify outdoor columns\n",
    "outdoor_columns = [col for col in df.columns if col.startswith(\"outdoor_pool_shared\")]\n",
    "\n",
    "# Get indices where outdoor features detected\n",
    "indices_with_outdoor = df[df[\"outdoor_pool_private\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 5\n",
    "if test_index < len(indices_with_outdoor):\n",
    "    index_to_check = indices_with_outdoor[test_index]\n",
    "    true_outdoor_columns = [col for col in outdoor_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\", \"has_outdoor\"] + true_outdoor_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "    \n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected outdoor features ===\")\n",
    "    print(df_check.to_string(max_colwidth=2000))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_outdoor)} rows with has_outdoor == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b2773-14fe-4200-bad8-0b8d8992255f",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5aa60480-0265-4f95-a409-c8b42cee2779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:25.997471Z",
     "start_time": "2025-07-13T13:16:25.992539Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_bath_bed_game_columns(df):\n",
    "    # Mapping of columns to target phrases\n",
    "    item_patterns = {\n",
    "        \"bath_item_shampoo\": \"shampoo\",\n",
    "        \"bath_item_body_soap\": \"body soap\",\n",
    "        \"bath_item_conditioner\": \"conditioner\",\n",
    "        \"kitchen_item_baking_sheet\": \"baking sheet\",\n",
    "        \"bed_item_bed_linens\": \"bed linens\",\n",
    "        \"game_item_games\": \"games\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_bath_bed_game_items\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in item_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # For detection efficiency\n",
    "    item_terms = list(item_patterns.values())\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Set general flag if any detected\n",
    "        if any(any(term in a for term in item_terms) for a in amenities_lower):\n",
    "            new_cols[\"has_bath_bed_game_items\"].at[idx] = True\n",
    "\n",
    "        # Set individual columns\n",
    "        for amenity_lower in amenities_lower:\n",
    "            for col_name, term in item_patterns.items():\n",
    "                if term in amenity_lower:\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04c1463b-6e81-4788-9f2b-86a31043bfa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:26.083364Z",
     "start_time": "2025-07-13T13:16:26.079740Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_bath_bed_game_items(df):\n",
    "    item_columns = [col for col in df.columns if col.startswith((\"bath_item_\", \"bed_item_\", \"game_item_\", \"kitchen_item_\"))]\n",
    "    item_counts = df[item_columns].sum().sort_values(ascending=False)\n",
    "    return item_counts.reset_index().rename(columns={\"index\": \"item_type\", 0: \"count\"})\n",
    "\n",
    "def count_bath_bed_game_with_and_without(df):\n",
    "    item_columns = [col for col in df.columns if col.startswith((\"bath_item_\", \"bed_item_\", \"game_item_\", \"kitchen_item_\"))]\n",
    "    has_type = df[item_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_bath_bed_game_items\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_bath_bed_game_items\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8cd18c4-0f81-44ee-926d-31251c615f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:26.596629Z",
     "start_time": "2025-07-13T13:16:26.140638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 7174, 'without_type': 0}\n",
      "                   item_type  count\n",
      "0        bed_item_bed_linens   6464\n",
      "1          bath_item_shampoo   4383\n",
      "2        bath_item_body_soap   3640\n",
      "3  kitchen_item_baking_sheet   2826\n",
      "4      bath_item_conditioner   1103\n",
      "5            game_item_games    730\n"
     ]
    }
   ],
   "source": [
    "df = create_bath_bed_game_columns(df)\n",
    "\n",
    "# Get counts\n",
    "item_counts_df = count_bath_bed_game_items(df)\n",
    "item_summary = count_bath_bed_game_with_and_without(df)\n",
    "\n",
    "print(item_summary)\n",
    "print(item_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "696c59b0-0753-4579-a27c-00c8e857c0f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:26.694111Z",
     "start_time": "2025-07-13T13:16:26.676020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 12 | Displaying amenities and detected bath/bed/game items ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              amenities  has_bath_bed_game_items  kitchen_item_baking_sheet  bed_item_bed_linens\n",
      "12  [\"Dishes and silverware\", \"Bed linens\", \"Cleaning available during stay\", \"Laundromat nearby\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Refrigerator\", \"Hangers\", \"Wifi\", \"Dishwasher\", \"Cooking basics\", \"Smoking allowed\", \"Essentials\", \"Coffee maker\", \"Hair dryer\", \"Extra pillows and blankets\", \"Heating\", \"Hot water kettle\", \"Shared patio or balcony\", \"Dedicated workspace\", \"Kitchen\", \"Single level home\", \"Iron\", \"Wine glasses\", \"Free street parking\", \"Washer\", \"Stove\", \"Hot water\", \"Baking sheet\", \"Room-darkening shades\", \"Host greets you\", \"Private entrance\", \"Oven\", \"Dining table\", \"TV with standard cable\", \"Microwave\"]                     True                       True                 True\n"
     ]
    }
   ],
   "source": [
    "# Identify item columns\n",
    "item_columns = [col for col in df.columns if col.startswith((\"bath_item_\", \"bed_item_\", \"game_item_\", \"kitchen_item_\"))]\n",
    "\n",
    "# Get indices where items detected\n",
    "indices_with_items = df[df[\"has_bath_bed_game_items\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "if test_index < len(indices_with_items):\n",
    "    index_to_check = indices_with_items[test_index]\n",
    "    true_item_columns = [col for col in item_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\", \"has_bath_bed_game_items\"] + true_item_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "    \n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected bath/bed/game items ===\")\n",
    "    print(df_check.to_string(max_colwidth=2000))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_items)} rows with has_bath_bed_game_items == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ef746-dfea-4a18-a3e9-38698bb3d73d",
   "metadata": {},
   "source": [
    "### WIFI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af4fea43-ca30-4c79-9d8f-26e7ebae46e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:26.800207Z",
     "start_time": "2025-07-13T13:16:26.794947Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_wifi_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_wifi\": pd.Series(False, index=df.index),\n",
    "        \"wifi_speed_mbps\": pd.Series(None, index=df.index, dtype=float)\n",
    "    }\n",
    "\n",
    "    # Loosened detection\n",
    "    wifi_terms_pattern = re.compile(\n",
    "        r\"(wifi|wi-fi|Ethernet|wireless internet)\"\n",
    "    )\n",
    "\n",
    "    # Improved speed extraction pattern:\n",
    "    wifi_speed_pattern = re.compile(\n",
    "        r\"(?:wifi.*?(?:–|-)\\s*)?(\\d{1,4}(?:[.,]\\d+)?)\\s*(?:mbps|mb/s|mps)\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        found_wifi = False\n",
    "        speeds = []\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            if wifi_terms_pattern.search(amenity):\n",
    "                found_wifi = True\n",
    "\n",
    "                match = wifi_speed_pattern.search(amenity)\n",
    "                if match:\n",
    "                    speed_str = match.group(1).replace(\",\", \".\")\n",
    "                    try:\n",
    "                        speed_value = float(speed_str)\n",
    "                        speeds.append(speed_value)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "        if found_wifi:\n",
    "            new_cols[\"has_wifi\"].at[idx] = True\n",
    "            if speeds:\n",
    "                new_cols[\"wifi_speed_mbps\"].at[idx] = max(speeds)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e3ce2fc-9070-490f-9af7-4bab4cbe870e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:26.888911Z",
     "start_time": "2025-07-13T13:16:26.881907Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_wifi_summary(df):\n",
    "    has_wifi = df[\"has_wifi\"] == True\n",
    "    has_speed = df[\"wifi_speed_mbps\"].notna()\n",
    "\n",
    "    with_speed = (has_wifi & has_speed).sum()\n",
    "    without_speed = (has_wifi & ~has_speed).sum()\n",
    "    total_wifi = has_wifi.sum()\n",
    "\n",
    "    return {\n",
    "        \"total_wifi\": int(total_wifi),\n",
    "        \"with_speed\": int(with_speed),\n",
    "        \"without_speed\": int(without_speed)\n",
    "    }\n",
    "\n",
    "def wifi_speed_distribution(df, bins=None):\n",
    "    wifi_speeds = df.loc[df[\"wifi_speed_mbps\"].notna(), \"wifi_speed_mbps\"]\n",
    "    if bins:\n",
    "        return pd.cut(wifi_speeds, bins=bins).value_counts().sort_index()\n",
    "    else:\n",
    "        return wifi_speeds.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e5b5a28-1ad6-4849-8f64-b124e8873f15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:27.316713Z",
     "start_time": "2025-07-13T13:16:27.047883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_wifi': 8659, 'with_speed': 665, 'without_speed': 7994}\n",
      "    has_wifi  wifi_speed_mbps\n",
      "0       True              NaN\n",
      "1       True              NaN\n",
      "2       True              NaN\n",
      "3       True              NaN\n",
      "4       True              NaN\n",
      "5      False              NaN\n",
      "7       True              NaN\n",
      "9       True              NaN\n",
      "10      True              NaN\n",
      "11      True              NaN\n"
     ]
    }
   ],
   "source": [
    "df = create_wifi_columns(df)\n",
    "\n",
    "# Count summary\n",
    "wifi_summary = count_wifi_summary(df)\n",
    "print(wifi_summary)\n",
    "\n",
    "# Optional: Display raw speeds for review\n",
    "print(df[[\"has_wifi\", \"wifi_speed_mbps\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2dfa3df5-6034-4b40-8e6e-3b1d0c12d50a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:27.422876Z",
     "start_time": "2025-07-13T13:16:27.384014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 2839 | Displaying amenities and detected WiFi info ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       amenities  has_wifi  wifi_speed_mbps\n",
      "2839  [\"Portable fans\", \"Dishes and silverware\", \"Garden view\", \"Bed linens\", \"TV\", \"Hangers\", \"Refrigerator\", \"Shampoo\", \"Cleaning products\", \"Cooking basics\", \"Essentials\", \"Coffee maker\", \"Hair dryer\", \"Heating\", \"Hot water kettle\", \"Self check-in\", \"Fast wifi \\u2013 206 Mbps\", \"Dedicated workspace\", \"Lockbox\", \"Kitchen\", \"Free street parking\", \"Stove\", \"Clothing storage: wardrobe\", \"Smoke alarm\", \"Hot water\", \"Room-darkening shades\", \"Body soap\", \"Free parking on premises\", \"Private entrance\", \"Mini fridge\", \"Dining table\", \"Free washer \\u2013 In unit\", \"Microwave\"]      True            206.0\n"
     ]
    }
   ],
   "source": [
    "# Get indices where WiFi detected\n",
    "indices_with_wifi = df[df[\"wifi_speed_mbps\"].notna()].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 102\n",
    "if test_index < len(indices_with_wifi):\n",
    "    index_to_check = indices_with_wifi[test_index]\n",
    "    columns_to_display = [\"amenities\", \"has_wifi\", \"wifi_speed_mbps\"]\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected WiFi info ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_wifi)} rows with has_wifi == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896111c8-f58b-41ac-8a1e-bf08231dc75e",
   "metadata": {},
   "source": [
    "### Backyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa51abba-0dbc-432d-bcaf-1582487f89cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:27.676170Z",
     "start_time": "2025-07-13T13:16:27.662167Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_backyard_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_backyard\": pd.Series(False, index=df.index),\n",
    "        \"backyard_shared\": pd.Series(False, index=df.index),\n",
    "        \"backyard_fully_fenced\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "\n",
    "    # Detection patterns\n",
    "    backyard_pattern = re.compile(r\"\\bbackyard|garten\\b\")\n",
    "    shared_pattern = re.compile(r\"\\b(shared backyard\\b)\")\n",
    "    fenced_pattern = re.compile(r\"\\b(backyard \\u2013 fully fenced)\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        found_backyard = False\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            if backyard_pattern.search(amenity):\n",
    "                found_backyard = True\n",
    "\n",
    "                if shared_pattern.search(amenity):\n",
    "                    new_cols[\"backyard_shared\"].at[idx] = True\n",
    "\n",
    "                if fenced_pattern.search(amenity):\n",
    "                    new_cols[\"backyard_fully_fenced\"].at[idx] = True\n",
    "\n",
    "        if found_backyard:\n",
    "            new_cols[\"has_backyard\"].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "28499118-aaef-41b0-ba40-0186ef975bf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:27.749502Z",
     "start_time": "2025-07-13T13:16:27.744301Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_backyard_features(df):\n",
    "    backyard_columns = [\"has_backyard\", \"backyard_shared\", \"backyard_fully_fenced\"]\n",
    "    backyard_counts = df[backyard_columns].sum().sort_values(ascending=False)\n",
    "    return backyard_counts.reset_index().rename(columns={\"index\": \"backyard_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6af2b4f-e890-4f3c-886c-03c220316626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:28.241764Z",
     "start_time": "2025-07-13T13:16:27.870106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        backyard_feature  count\n",
      "0           has_backyard   2100\n",
      "1        backyard_shared    918\n",
      "2  backyard_fully_fenced    852\n"
     ]
    }
   ],
   "source": [
    "df = create_backyard_columns(df)\n",
    "\n",
    "# Display counts\n",
    "backyard_counts_df = count_backyard_features(df)\n",
    "print(backyard_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3651f746-67a3-4acb-a3f0-0c9968836c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:28.423077Z",
     "start_time": "2025-07-13T13:16:28.413631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 362 | Displaying amenities and detected backyard features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                amenities  has_backyard  backyard_shared  backyard_fully_fenced\n",
      "362  [\"Keypad\", \"Drying rack for clothing\", \"Portable fans\", \"Shared backyard \\u2013 Fully fenced\", \"Shower gel\", \"Dishes and silverware\", \"Garden view\", \"Bed linens\", \"Paid street parking off premises\", \"Cleaning available during stay\", \"Laundromat nearby\", \"Long term stays allowed\", \"Outdoor dining area\", \"Coffee\", \"Hangers\", \"Wifi\", \"High chair\", \"Shampoo\", \"Cleaning products\", \"Window guards\", \"Paid pack \\u2019n play/travel crib - available upon request\", \"Electric stove\", \"Cooking basics\", \"Crib - available upon request\", \"Essentials\", \"Coffee maker\", \"Hair dryer\", \"Heating\", \"Carbon monoxide alarm\", \"Hot water kettle\", \"Self check-in\", \"Kitchen\", \"Outdoor furniture\", \"Mit 3 Sterne Gefrierfach  refrigerator\", \"Iron\", \"Wine glasses\", \"Clothing storage: wardrobe\", \"43 inch HDTV with Amazon Prime Video, Fire TV, Netflix, premium cable, Disney+\", \"Hot water\", \"Room-darkening shades\", \"Body soap\", \"Smoke alarm\", \"Private entrance\", \"Dining table\", \"Toaster\", \"Courtyard view\", \"Free washer \\u2013 In unit\", \"Microwave\"]          True             True                   True\n"
     ]
    }
   ],
   "source": [
    "# Identify backyard columns\n",
    "backyard_columns = [\"has_backyard\", \"backyard_shared\", \"backyard_fully_fenced\"]\n",
    "\n",
    "# Get indices where backyard features detected\n",
    "indices_with_backyard = df[df[\"has_backyard\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 97\n",
    "if test_index < len(indices_with_backyard):\n",
    "    index_to_check = indices_with_backyard[test_index]\n",
    "    true_backyard_columns = [col for col in backyard_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_backyard_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected backyard features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_backyard)} rows with has_backyard == True; test_index {test_index} is out of range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2c7d4-57bc-450e-b2ba-447b8cd41e65",
   "metadata": {},
   "source": [
    "### Balcony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a421d2e-2a05-47f6-85c1-3e3ca9ece3e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:28.512403Z",
     "start_time": "2025-07-13T13:16:28.508023Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_balcony_columns(df):\n",
    "    # Initialize column\n",
    "    new_cols = {\n",
    "        \"has_balcony\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "\n",
    "    # Patterns for \"balcony\", \"balkon\", \"patio\"\n",
    "    balcony_pattern = re.compile(\n",
    "        r\"\\b(balcony|balkon|patio)\\b\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            if balcony_pattern.search(amenity):\n",
    "                new_cols[\"has_balcony\"].at[idx] = True\n",
    "                break  # no need to check further for this row\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2159aa4c-479b-4eea-8128-10cee1d59f0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:28.611103Z",
     "start_time": "2025-07-13T13:16:28.608621Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_balcony(df):\n",
    "    count = df[\"has_balcony\"].sum()\n",
    "    return {\"total_with_balcony\": int(count)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c8a1ef3d-591c-43cc-a33d-217d6615daeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:28.905532Z",
     "start_time": "2025-07-13T13:16:28.703925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_with_balcony': 2987}\n"
     ]
    }
   ],
   "source": [
    "df = create_balcony_columns(df)\n",
    "\n",
    "# Count\n",
    "balcony_summary = count_balcony(df)\n",
    "print(balcony_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d829481-9dd1-460b-8a0c-d9f00f677768",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:29.022645Z",
     "start_time": "2025-07-13T13:16:29.011009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 21 | Displaying amenities and detected balcony ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           amenities  has_balcony\n",
      "21  [\"Drying rack for clothing\", \"Portable fans\", \"Shower gel\", \"Dishes and silverware\", \"City skyline view\", \"Bed linens\", \"Laundromat nearby\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Outdoor dining area\", \"Refrigerator\", \"Hangers\", \"Fast wifi \\u2013 213 Mbps\", \"Shampoo\", \"Dishwasher\", \"Cleaning products\", \"Freezer\", \"Electric stove\", \"Conditioner\", \"Bidet\", \"Yamaha sound system with Bluetooth and aux\", \"Cooking basics\", \"55 inch HDTV with Amazon Prime Video, Apple TV, Netflix\", \"Essentials\", \"Free dryer \\u2013 In building\", \"Extra pillows and blankets\", \"Hair dryer\", \"Central heating\", \"Hot water kettle\", \"Coffee maker: Nespresso, pour-over coffee\", \"Bread maker\", \"Self check-in\", \"Dedicated workspace\", \"Smart lock\", \"Kitchen\", \"Outdoor furniture\", \"Iron\", \"Paid parking off premises\", \"Wine glasses\", \"Free washer \\u2013 In building\", \"Hot water\", \"Body soap\", \"Room-darkening shades\", \"Baking sheet\", \"Ethernet connection\", \"Oven\", \"Toaster\", \"Dining table\", \"Private patio or balcony\", \"Microwave\"]         True\n"
     ]
    }
   ],
   "source": [
    "# Get indices with balconies\n",
    "indices_with_balcony = df[df[\"has_balcony\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 6\n",
    "if test_index < len(indices_with_balcony):\n",
    "    index_to_check = indices_with_balcony[test_index]\n",
    "    columns_to_display = [\"amenities\", \"has_balcony\"]\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected balcony ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_balcony)} rows with has_balcony == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41273eaf-48d4-479d-8a19-2bf6b7e46ddc",
   "metadata": {},
   "source": [
    "### Heating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64fc7d4d-60a8-408a-acb5-f2e212794025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:29.135965Z",
     "start_time": "2025-07-13T13:16:29.132736Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_heating_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_heating\": pd.Series(False, index=df.index),\n",
    "        \"has_central_heating\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "\n",
    "    # Heating detection patterns\n",
    "    heating_pattern = re.compile(r\"\\b(heating)\\b\")\n",
    "    central_heating_pattern = re.compile(r\"\\b(central heating)\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            # Check for central heating\n",
    "            if central_heating_pattern.search(amenity):\n",
    "                new_cols[\"has_central_heating\"].at[idx] = True\n",
    "\n",
    "            # Check for any heating mention\n",
    "            if heating_pattern.search(amenity):\n",
    "                new_cols[\"has_heating\"].at[idx] = True\n",
    "\n",
    "            # If central heating detected, also ensure has_heating is True\n",
    "            if new_cols[\"has_central_heating\"].at[idx]:\n",
    "                new_cols[\"has_heating\"].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae74b89f-6b87-47df-88b9-e095a96b282b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:29.240162Z",
     "start_time": "2025-07-13T13:16:29.237986Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_heating_features(df):\n",
    "    heating_columns = [\"has_heating\", \"has_central_heating\"]\n",
    "    heating_counts = df[heating_columns].sum().sort_values(ascending=False)\n",
    "    return heating_counts.reset_index().rename(columns={\"index\": \"heating_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9816f202-c574-4e2f-881a-eb7f4042449d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:30.806756Z",
     "start_time": "2025-07-13T13:16:29.321033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       heating_feature  count\n",
      "0          has_heating   7703\n",
      "1  has_central_heating   2487\n"
     ]
    }
   ],
   "source": [
    "df = create_heating_columns(df)\n",
    "\n",
    "# Display counts\n",
    "heating_counts_df = count_heating_features(df)\n",
    "print(heating_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e4f0dcd2-6dfb-4d0e-8a0b-a15b394d5fb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:30.875989Z",
     "start_time": "2025-07-13T13:16:30.864638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 9 | Displaying amenities and detected heating features ===\n",
      "                                                                                                                                                                                                      amenities  has_heating\n",
      "9  [\"Heating\", \"Host greets you\", \"Smoke alarm\", \"Coffee maker\", \"Dishes and silverware\", \"Kitchen\", \"Private entrance\", \"Ethernet connection\", \"Refrigerator\", \"TV\", \"Hangers\", \"Washer\", \"Wifi\", \"Hot water\"]         True\n"
     ]
    }
   ],
   "source": [
    "# Identify heating columns\n",
    "heating_columns = [\"has_heating\", \"has_central_heating\"]\n",
    "\n",
    "# Get indices where heating is detected\n",
    "indices_with_heating = df[df[\"has_heating\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "if test_index < len(indices_with_heating):\n",
    "    index_to_check = indices_with_heating[test_index]\n",
    "    true_heating_columns = [col for col in heating_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_heating_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected heating features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_heating)} rows with has_heating == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b036452-5114-4af9-be67-592dc5418345",
   "metadata": {},
   "source": [
    "### Hottub and Bathtub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dad32b63-8451-4b79-9bcc-343657fe3447",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:30.986316Z",
     "start_time": "2025-07-13T13:16:30.982172Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_hottub_bathtub_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_hottub\": pd.Series(False, index=df.index),\n",
    "        \"has_bathtub\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "\n",
    "    # Patterns\n",
    "    hottub_pattern = re.compile(r\"\\b(hot tub)\\b\")\n",
    "    bathtub_pattern = re.compile(r\"\\b(bathtub)\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            # Check for hot tub\n",
    "            if hottub_pattern.search(amenity):\n",
    "                new_cols[\"has_hottub\"].at[idx] = True\n",
    "\n",
    "            # Check for bathtub\n",
    "            if bathtub_pattern.search(amenity):\n",
    "                new_cols[\"has_bathtub\"].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0ccd5a42-917a-4a39-812e-2afcb91bd1bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:31.076127Z",
     "start_time": "2025-07-13T13:16:31.071693Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_hottub_bathtub(df):\n",
    "    columns = [\"has_hottub\", \"has_bathtub\"]\n",
    "    counts = df[columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"feature\", 0: \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d75c083f-f1f7-4ab3-8513-c387827254d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:31.362526Z",
     "start_time": "2025-07-13T13:16:31.143673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature  count\n",
      "0  has_bathtub   2692\n",
      "1   has_hottub    135\n"
     ]
    }
   ],
   "source": [
    "df = create_hottub_bathtub_columns(df)\n",
    "\n",
    "# Get counts\n",
    "ht_bt_counts_df = count_hottub_bathtub(df)\n",
    "print(ht_bt_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f76825a-2d35-4b78-b496-0849b74928ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:31.428539Z",
     "start_time": "2025-07-13T13:16:31.422898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 910 | Displaying amenities and detected hot tub / bathtub features ===\n",
      "                                                                                                                            amenities  has_hottub\n",
      "910  [\"Heating\", \"Dryer\", \"Elevator\", \"Kitchen\", \"Pets allowed\", \"Wifi\", \"Essentials\", \"Hot tub\", \"Washer\", \"TV with standard cable\"]        True\n"
     ]
    }
   ],
   "source": [
    "# Identify relevant columns\n",
    "columns = [\"has_hottub\", \"has_bathtub\"]\n",
    "\n",
    "# Get indices where hot tub or bathtub detected\n",
    "indices_with_features = df[(df[\"has_hottub\"] == True) ].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "if test_index < len(indices_with_features):\n",
    "    index_to_check = indices_with_features[test_index]\n",
    "    true_columns = [col for col in columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected hot tub / bathtub features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_features)} rows with hot tub or bathtub detected; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07451f-633b-42c9-b83a-8d042b6f5abc",
   "metadata": {},
   "source": [
    "### Washer and dryer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "abdd888c-6be9-4bad-abfa-9412d1151d39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:31.512080Z",
     "start_time": "2025-07-13T13:16:31.507906Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_washer_dryer_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_washer\": pd.Series(False, index=df.index),\n",
    "        \"washer_paid\": pd.Series(False, index=df.index),\n",
    "        \"washer_in_building\": pd.Series(False, index=df.index),\n",
    "        \"has_dryer\": pd.Series(False, index=df.index),\n",
    "        \"dryer_paid\": pd.Series(False, index=df.index),\n",
    "        \"dryer_in_building\": pd.Series(False, index=df.index),\n",
    "    }\n",
    "\n",
    "    # Patterns\n",
    "    washer_pattern = re.compile(r\"\\b(washer)\\b\")\n",
    "    dryer_pattern = re.compile(r\"\\b(dryer)\\b\")\n",
    "    paid_pattern = re.compile(r\"\\b(paid)\\b\")\n",
    "    in_building_pattern = re.compile(r\"\\b(in building|on premises)\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            # Washer detection\n",
    "            if washer_pattern.search(amenity):\n",
    "                new_cols[\"has_washer\"].at[idx] = True\n",
    "                if paid_pattern.search(amenity):\n",
    "                    new_cols[\"washer_paid\"].at[idx] = True\n",
    "                if in_building_pattern.search(amenity):\n",
    "                    new_cols[\"washer_in_building\"].at[idx] = True\n",
    "\n",
    "            # Dryer detection\n",
    "            if dryer_pattern.search(amenity):\n",
    "                new_cols[\"has_dryer\"].at[idx] = True\n",
    "                if paid_pattern.search(amenity):\n",
    "                    new_cols[\"dryer_paid\"].at[idx] = True\n",
    "                if in_building_pattern.search(amenity):\n",
    "                    new_cols[\"dryer_in_building\"].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f23c780-970d-499d-8a62-458c46bd2ea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:31.568169Z",
     "start_time": "2025-07-13T13:16:31.564052Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_washer_dryer_features(df):\n",
    "    columns = [\n",
    "        \"has_washer\", \"washer_paid\", \"washer_in_building\",\n",
    "        \"has_dryer\", \"dryer_paid\", \"dryer_in_building\"\n",
    "    ]\n",
    "    counts = df[columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"feature\", 0: \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "758133cd-b480-41c5-aca6-c861561f56cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:32.079335Z",
     "start_time": "2025-07-13T13:16:31.614480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              feature  count\n",
      "0           has_dryer   7075\n",
      "1          has_washer   6730\n",
      "2  washer_in_building    892\n",
      "3   dryer_in_building    583\n",
      "4         washer_paid    441\n",
      "5          dryer_paid    275\n"
     ]
    }
   ],
   "source": [
    "df = create_washer_dryer_columns(df)\n",
    "\n",
    "# Get counts\n",
    "washer_dryer_counts_df = count_washer_dryer_features(df)\n",
    "print(washer_dryer_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9880f510-f1fd-4fd3-bc0c-be74668992e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:32.148404Z",
     "start_time": "2025-07-13T13:16:32.141532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 3606 | Displaying amenities and detected washer/dryer features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    amenities  has_washer  washer_paid  washer_in_building  has_dryer  dryer_paid  dryer_in_building\n",
      "3606  [\"Paid dryer \\u2013 In building\", \"Shower gel\", \"Dishes and silverware\", \"Bed linens\", \"Lock on bedroom door\", \"Paid washer \\u2013 In building\", \"Laundromat nearby\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Hangers\", \"Shampoo\", \"Cleaning products\", \"Ceiling fan\", \"Private backyard \\u2013 Fully fenced\", \"Fast wifi \\u2013 101 Mbps\", \"Fire extinguisher\", \"First aid kit\", \"Essentials\", \"Coffee maker\", \"Hair dryer\", \"Extra pillows and blankets\", \"Heating\", \"Carbon monoxide alarm\", \"Elevator\", \"Dedicated workspace\", \"Private living room\", \"Iron\", \"Paid parking off premises\", \"Free street parking\", \"Clothing storage: wardrobe and dresser\", \"Hot water\", \"Body soap\", \"Room-darkening shades\", \"Smoke alarm\", \"Host greets you\", \"Private entrance\", \"Unterschiedlich conditioner\", \"Courtyard view\", \"Mini fridge\"]        True         True                True       True        True               True\n"
     ]
    }
   ],
   "source": [
    "# Identify columns\n",
    "columns = [\n",
    "    \"has_washer\", \"washer_paid\", \"washer_in_building\",\n",
    "    \"has_dryer\", \"dryer_paid\", \"dryer_in_building\"\n",
    "]\n",
    "\n",
    "# Get indices where washer or dryer detected\n",
    "indices_with_features = df[\n",
    "    (df[\"has_washer\"] == True) & (df[\"dryer_paid\"] == True)\n",
    "].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 17\n",
    "if test_index < len(indices_with_features):\n",
    "    index_to_check = indices_with_features[test_index]\n",
    "    true_columns = [col for col in columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected washer/dryer features ===\")\n",
    "    print(df_check.to_string(max_colwidth=2500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_features)} rows with washer or dryer detected; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ffb6c3-412a-4e79-87eb-a02e043a207b",
   "metadata": {},
   "source": [
    "### Hoesekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0ca558f4-9728-4d6c-8e49-6dc88c2b1117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:32.276693Z",
     "start_time": "2025-07-13T13:16:32.261417Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_housekeeping_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"housekeeping_included\": pd.Series(False, index=df.index),\n",
    "        \"housekeeping_available_at_cost\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "\n",
    "    housekeeping_pattern = re.compile(\n",
    "        r\"\\b(housekeeping)\\b\"\n",
    "    )\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            # Check for housekeeping included\n",
    "            if housekeeping_pattern.search(amenity):\n",
    "                if(\"cost\" in amenity):\n",
    "                    new_cols[\"housekeeping_available_at_cost\"].at[idx] = True\n",
    "                else:\n",
    "                    new_cols[\"housekeeping_included\"].at[idx] = True\n",
    "                    \n",
    "                \n",
    "                \n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c4413d8-133c-4327-963a-d3cfbbc21d82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:32.392561Z",
     "start_time": "2025-07-13T13:16:32.389445Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_housekeeping_features(df):\n",
    "    housekeeping_columns = [\"housekeeping_included\", \"housekeeping_available_at_cost\"]\n",
    "    counts = df[housekeeping_columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"housekeeping_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "35811ec2-bd48-4bb6-a5cb-93588b375cf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:32.625199Z",
     "start_time": "2025-07-13T13:16:32.475911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             housekeeping_feature  count\n",
      "0  housekeeping_available_at_cost    325\n",
      "1           housekeeping_included     35\n"
     ]
    }
   ],
   "source": [
    "df = create_housekeeping_columns(df)\n",
    "\n",
    "# Get counts\n",
    "housekeeping_counts_df = count_housekeeping_features(df)\n",
    "print(housekeeping_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "08203f8b-e2e6-4b46-9f3b-3ea7698b72b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:32.657181Z",
     "start_time": "2025-07-13T13:16:32.648677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 475 | Displaying amenities and detected housekeeping features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           amenities  housekeeping_included\n",
      "475  [\"Bathtub\", \"Drying rack for clothing\", \"Shower gel\", \"Dishes and silverware\", \"Garden view\", \"Bed linens\", \"Laundromat nearby\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Seppelfricke stainless steel oven\", \"Books and reading material\", \"Hangers\", \"Shampoo\", \"Dishwasher\", \"Cleaning products\", \"Wifi \\u2013 22 Mbps\", \"Conditioner\", \"Cooking basics\", \"Fire extinguisher\", \"Essentials\", \"Blender\", \"Housekeeping available Saturday - included with your stay\", \"Other stainless steel gas stove\", \"Hair dryer\", \"Extra pillows and blankets\", \"Hot water kettle\", \"Central heating\", \"Elevator\", \"Dedicated workspace\", \"Kitchen\", \"Iron\", \"Wine glasses\", \"Free street parking\", \"Siemens refrigerator\", \"Clothing storage: wardrobe and dresser\", \"Hot water\", \"Body soap\", \"Room-darkening shades\", \"Smoke alarm\", \"Baking sheet\", \"Host greets you\", \"Dining table\", \"Courtyard view\", \"Free washer \\u2013 In unit\"]                   True\n"
     ]
    }
   ],
   "source": [
    "# Identify columns\n",
    "housekeeping_columns = [\"housekeeping_included\", \"housekeeping_available_at_cost\"]\n",
    "\n",
    "# Get indices where housekeeping detected\n",
    "indices_with_housekeeping = df[\n",
    "    (df[\"housekeeping_included\"] == True) | (df[\"housekeeping_available_at_cost\"] == True)\n",
    "].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 3\n",
    "if test_index < len(indices_with_housekeeping):\n",
    "    index_to_check = indices_with_housekeeping[test_index]\n",
    "    true_columns = [col for col in housekeeping_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected housekeeping features ===\")\n",
    "    print(df_check.to_string(max_colwidth=2500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_housekeeping)} rows with housekeeping detected; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6304e99e-3f36-44fc-a638-9b24a30271a5",
   "metadata": {},
   "source": [
    "### Baby and children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "682bb409-0783-4c74-b3a3-6ab44d8b4966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:32.781102Z",
     "start_time": "2025-07-13T13:16:32.778063Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_baby_columns(df):\n",
    "    # Mapping of columns to detection phrases\n",
    "    baby_patterns = {\n",
    "        \"baby_bath\": r\"\\bbaby bath\\b\",\n",
    "        \"baby_monitor\": r\"\\bbaby monitor\\b\",\n",
    "        \"baby_safety\": r\"\\b(baby safety|child safety|baby gate|safety gate|cabinet locks)\\b\",\n",
    "        \"children_books_and_toys\": r\"\\b(children's books and toys|children books and toys|kids books and toys|toys|books for kids|books and toys)\\b\",\n",
    "        \"crib\": r\"\\b(crib|baby bed|cot)\\b\",\n",
    "        \"high_chair\": r\"\\b(high chair|baby chair)\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {}\n",
    "    for col in baby_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity_lower in amenities_lower:\n",
    "            for col_name, pattern in baby_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7c124b3a-d984-43e9-a375-0ef24f452ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:32.844152Z",
     "start_time": "2025-07-13T13:16:32.841854Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_baby_features(df):\n",
    "    baby_columns = [\n",
    "        \"baby_bath\",\n",
    "        \"baby_monitor\",\n",
    "        \"baby_safety\",\n",
    "        \"children_books_and_toys\",\n",
    "        \"crib\",\n",
    "        \"high_chair\"\n",
    "    ]\n",
    "    counts = df[baby_columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"baby_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "141286e6-99e3-4907-8f2e-52f1dee93251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:34.360377Z",
     "start_time": "2025-07-13T13:16:32.910636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              baby_feature  count\n",
      "0                     crib   2442\n",
      "1               high_chair   1721\n",
      "2  children_books_and_toys    802\n",
      "3                baby_bath    355\n",
      "4             baby_monitor     76\n",
      "5              baby_safety     58\n"
     ]
    }
   ],
   "source": [
    "df = create_baby_columns(df)\n",
    "\n",
    "# Get counts\n",
    "baby_counts_df = count_baby_features(df)\n",
    "print(baby_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3558880-088e-4acc-b76e-89a31bc02097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:34.523622Z",
     "start_time": "2025-07-13T13:16:34.512806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 29 | Displaying amenities and detected baby features ===\n",
      "                                                                                                                                                                                                                                                                amenities  crib  high_chair\n",
      "29  [\"Heating\", \"Host greets you\", \"Smoke alarm\", \"High chair\", \"Crib\", \"Kitchen\", \"Iron\", \"Luggage dropoff allowed\", \"Refrigerator\", \"Free street parking\", \"Long term stays allowed\", \"Essentials\", \"Hangers\", \"Coffee maker\", \"Wifi\", \"TV\", \"Hair dryer\", \"Hot water\"]  True        True\n"
     ]
    }
   ],
   "source": [
    "# Identify baby columns\n",
    "baby_columns = [\n",
    "    \"baby_bath\",\n",
    "    \"baby_monitor\",\n",
    "    \"baby_safety\",\n",
    "    \"children_books_and_toys\",\n",
    "    \"crib\",\n",
    "    \"high_chair\"\n",
    "]\n",
    "\n",
    "# Get indices where any baby feature is detected\n",
    "indices_with_baby = df[df[baby_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 12\n",
    "if test_index < len(indices_with_baby):\n",
    "    index_to_check = indices_with_baby[test_index]\n",
    "    true_columns = [col for col in baby_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected baby features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_baby)} rows with baby features detected; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1f63c-d96f-4299-9637-555303e682e3",
   "metadata": {},
   "source": [
    "### Variuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "99e6dcf5-4425-46af-a5f3-58e9c6e72937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:34.641500Z",
     "start_time": "2025-07-13T13:16:34.635546Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_miscellaneous_columns(df):\n",
    "    # Mapping of column names to detection patterns\n",
    "    misc_patterns = {\n",
    "        \"luggage_dropoff_allowed\": r\"\\bluggage dropoff allowed\\b\",\n",
    "        \"long_term_stays_allowed\": r\"\\blong term stays allowed\\b\",\n",
    "        \"air_conditioning\": r\"\\bair conditioning\\b\",\n",
    "        \"pets_allowed\": r\"\\b(pets allowed|pet friendly)\\b\",\n",
    "        \"ping_pong_table\": r\"\\bping pong table\\b\",\n",
    "        \"host_greets_you\": r\"\\bhost greets you\\b\",\n",
    "        \"pool_table\": r\"\\bpool table\\b\",\n",
    "        \"private_entrance\": r\"\\bprivate entrance\\b\",\n",
    "        \"workspace\": r\"\\b(workspace|dedicated workspace|desk|working space|work space)\\b\"\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {}\n",
    "    for col in misc_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity_lower in amenities_lower:\n",
    "            for col_name, pattern in misc_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c12ed629-d685-41b3-adfa-bf67939024c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:34.712117Z",
     "start_time": "2025-07-13T13:16:34.706389Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_miscellaneous_features(df):\n",
    "    misc_columns = [\n",
    "        \"luggage_dropoff_allowed\",\n",
    "        \"long_term_stays_allowed\",\n",
    "        \"air_conditioning\",\n",
    "        \"pets_allowed\",\n",
    "        \"ping_pong_table\",\n",
    "        \"host_greets_you\",\n",
    "        \"private_entrance\",\n",
    "        \"workspace\"\n",
    "    ]\n",
    "    counts = df[misc_columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"misc_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aae288b5-97ea-4001-b189-0bf32e0a1a5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:37.105456Z",
     "start_time": "2025-07-13T13:16:35.418546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              misc_feature  count\n",
      "0                workspace   5344\n",
      "1  long_term_stays_allowed   4156\n",
      "2  luggage_dropoff_allowed   2531\n",
      "3         private_entrance   2514\n",
      "4          host_greets_you   2128\n",
      "5             pets_allowed   2066\n",
      "6         air_conditioning    631\n",
      "7          ping_pong_table    144\n"
     ]
    }
   ],
   "source": [
    "df = create_miscellaneous_columns(df)\n",
    "\n",
    "# Display counts\n",
    "misc_counts_df = count_miscellaneous_features(df)\n",
    "print(misc_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "24f4f488-c2db-413a-8c72-225a587c445b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:37.227190Z",
     "start_time": "2025-07-13T13:16:37.210628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 108 | Displaying amenities and detected miscellaneous features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  amenities  luggage_dropoff_allowed  long_term_stays_allowed  pets_allowed\n",
      "108  [\"Bathtub\", \"Drying rack for clothing\", \"Dishes and silverware\", \"Bed linens\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"TV\", \"Hangers\", \"Refrigerator\", \"Wifi\", \"Shampoo\", \"Cleaning products\", \"Pets allowed\", \"Paid pack \\u2019n play/travel crib - available upon request\", \"Cooking basics\", \"Essentials\", \"Clothing storage\", \"Coffee maker\", \"Hair dryer\", \"Hot water kettle\", \"Central heating\", \"High chair - available upon request\", \"Kitchen\", \"Single level home\", \"Iron\", \"Wine glasses\", \"Washer\", \"Stove\", \"Smoke alarm\", \"Hot water\", \"Room-darkening shades\", \"Body soap\", \"Baking sheet\", \"Paid parking lot off premises\", \"Oven\", \"Toaster\", \"Dining table\", \"Private patio or balcony\", \"Microwave\"]                     True                     True          True\n"
     ]
    }
   ],
   "source": [
    "# Identify miscellaneous columns\n",
    "misc_columns = [\n",
    "    \"luggage_dropoff_allowed\",\n",
    "    \"long_term_stays_allowed\",\n",
    "    \"air_conditioning\",\n",
    "    \"pets_allowed\",\n",
    "    \"ping_pong_table\",\n",
    "    \"host_greets_you\",\n",
    "    \"private_entrance\",\n",
    "    \"workspace\"\n",
    "]\n",
    "\n",
    "# Get indices where any miscellaneous feature is detected\n",
    "indices_with_misc = df[df[misc_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 80\n",
    "if test_index < len(indices_with_misc):\n",
    "    index_to_check = indices_with_misc[test_index]\n",
    "    true_columns = [col for col in misc_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected miscellaneous features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_misc)} rows with miscellaneous features detected; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8327f4-eef5-4b57-b8ad-3d34272de345",
   "metadata": {},
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8f31d7c2-35c2-4cbe-93d2-625269826c2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:37.369969Z",
     "start_time": "2025-07-13T13:16:37.356512Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_view_columns(df):\n",
    "    # Mapping columns to detection patterns\n",
    "    view_patterns = {\n",
    "        \"beach_view\": r\"\\bbeach view\\b\",\n",
    "        \"city_skyline_view\": r\"\\bcity skyline view\\b\",\n",
    "        \"desert_view\": r\"\\bdesert view\\b\",\n",
    "        \"garden_view\": r\"\\bgarden view\\b\",\n",
    "        \"pool_view\": r\"\\bpool view\\b\",\n",
    "\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {}\n",
    "    for col in view_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity_lower in amenities_lower:\n",
    "            for col_name, pattern in view_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "59769235-5968-42ba-817c-211fc3fa1041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:37.581467Z",
     "start_time": "2025-07-13T13:16:37.579380Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_view_features(df):\n",
    "    view_columns = [\"beach_view\", \"city_skyline_view\", \"desert_view\", \"garden_view\",\"pool_view\"]\n",
    "    counts = df[view_columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"view_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "639c6551-eeb1-422b-8d9f-19a7ecd29c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:38.595309Z",
     "start_time": "2025-07-13T13:16:37.649649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        view_feature  count\n",
      "0        garden_view    557\n",
      "1  city_skyline_view    411\n",
      "2          pool_view     14\n",
      "3         beach_view      6\n",
      "4        desert_view      1\n"
     ]
    }
   ],
   "source": [
    "df = create_view_columns(df)\n",
    "\n",
    "# Display counts\n",
    "view_counts_df = count_view_features(df)\n",
    "print(view_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "52a31bb2-6469-4df1-ac89-ffb376f4036f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:38.662560Z",
     "start_time": "2025-07-13T13:16:38.655845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 166 | Displaying amenities and detected miscellaneous features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     amenities  city_skyline_view\n",
      "166  [\"Dryer\", \"Drying rack for clothing\", \"Dishes and silverware\", \"City skyline view\", \"Bed linens\", \"Laundromat nearby\", \"Outdoor dining area\", \"Refrigerator\", \"Coffee\", \"Wifi\", \"Dishwasher\", \"32 inch TV with Amazon Prime Video\", \"Cooking basics\", \"Fire extinguisher\", \"Stainless steel oven\", \"Essentials\", \"Hair dryer\", \"Heating\", \"Hot water kettle\", \"Elevator\", \"Dedicated workspace\", \"Kitchen\", \"Iron\", \"Wine glasses\", \"Washer\", \"Smoke alarm\", \"Body soap\", \"Room-darkening shades\", \"Hot water\", \"Baking sheet\", \"Dining table\", \"Induction stove\", \"Toaster\", \"Private patio or balcony\"]               True\n"
     ]
    }
   ],
   "source": [
    "view_columns = [\"beach_view\", \"city_skyline_view\", \"desert_view\", \"garden_view\",\"pool_view\"]\n",
    "\n",
    "# Get indices where any miscellaneous feature is detected\n",
    "indices_with_misc = df[df[view_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 22\n",
    "if test_index < len(indices_with_misc):\n",
    "    index_to_check = indices_with_misc[test_index]\n",
    "    true_columns = [col for col in view_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected miscellaneous features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_misc)} rows with miscellaneous features detected; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d545fe-d00e-45b6-834e-0c1b0ade5cc8",
   "metadata": {},
   "source": [
    "### Gym "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6a8a71ea-d902-4684-b71d-100e796c3551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:38.730306Z",
     "start_time": "2025-07-13T13:16:38.726221Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_gym_columns(df):\n",
    "    # Mapping columns to detection patterns\n",
    "    gym_patterns = {\n",
    "        \"gym_private_in_building\": r\"\\bprivate gym in building\\b\",\n",
    "        \"gym_private_nearby\": r\"\\bprivate gym nearby\\b\",\n",
    "        \"gym_shared_in_building\": r\"\\bshared gym in building\\b\",\n",
    "        \"gym_shared_nearby\": r\"\\bshared gym nearby\\b\",\n",
    "        \"gym_private\": r\"\\bprivate gym\\b\",\n",
    "        \"gym_shared\": r\"\\bshared gym\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {}\n",
    "    for col in gym_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Optional general gym detection\n",
    "    new_cols[\"gym\"] = pd.Series(False, index=df.index)\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity_lower in amenities_lower:\n",
    "            # Mark specific private/shared patterns\n",
    "            for col_name, pattern in gym_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "            # General gym detection\n",
    "            if \"gym\" in amenity_lower:\n",
    "                new_cols[\"gym\"].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e46f3e6f-511d-4a96-a399-353bc46d30dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:38.801543Z",
     "start_time": "2025-07-13T13:16:38.798654Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_gym_features(df):\n",
    "    gym_columns = [\n",
    "        \"gym\",\n",
    "        \"gym_private\",\n",
    "        \"gym_private_in_building\",\n",
    "        \"gym_private_nearby\",\n",
    "        \"gym_shared\",\n",
    "        \"gym_shared_in_building\",\n",
    "        \"gym_shared_nearby\"\n",
    "    ]\n",
    "    counts = df[gym_columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"gym_feature\", 0: \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "281a94d4-1797-4b5d-aa11-9e608dd9c71a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:39.918212Z",
     "start_time": "2025-07-13T13:16:38.847486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               gym_feature  count\n",
      "0                      gym    179\n",
      "1               gym_shared     87\n",
      "2   gym_shared_in_building     53\n",
      "3        gym_shared_nearby     32\n",
      "4              gym_private     25\n",
      "5  gym_private_in_building     22\n",
      "6       gym_private_nearby      1\n"
     ]
    }
   ],
   "source": [
    "df = create_gym_columns(df)\n",
    "\n",
    "# Display counts\n",
    "gym_counts_df = count_gym_features(df)\n",
    "print(gym_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e698751e-0de7-48ed-b8b8-6ed39565d35c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.088024Z",
     "start_time": "2025-07-13T13:16:40.082263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 2431 | Displaying amenities and detected gym features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               amenities   gym  gym_shared  gym_shared_in_building\n",
      "2431  [\"Shared backyard \\u2013 Fully fenced\", \"Portable fans\", \"Shower gel\", \"Dishes and silverware\", \"Laundromat nearby\", \"Long term stays allowed\", \"Ping pong table\", \"Refrigerator\", \"Hangers\", \"TV\", \"EV charger\", \"Paid parking on premises\", \"Cooking basics\", \"Essentials\", \"Clothing storage\", \"Coffee maker\", \"Hair dryer\", \"Heating\", \"Exterior security cameras on property\", \"Elevator\", \"Dedicated workspace\", \"Iron\", \"Paid parking off premises\", \"Wine glasses\", \"Free street parking\", \"Stove\", \"Smoke alarm\", \"Body soap\", \"Hot water\", \"Shared gym in building\", \"Oven\", \"Private patio or balcony\"]  True        True                    True\n"
     ]
    }
   ],
   "source": [
    "# Identify gym columns\n",
    "gym_columns = [\n",
    "    \"gym\",\n",
    "    \"gym_private\",\n",
    "    \"gym_private_in_building\",\n",
    "    \"gym_private_nearby\",\n",
    "    \"gym_shared\",\n",
    "    \"gym_shared_in_building\",\n",
    "    \"gym_shared_nearby\"\n",
    "]\n",
    "\n",
    "# Get indices where any gym feature is detected\n",
    "indices_with_gym = df[df[gym_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 14\n",
    "if test_index < len(indices_with_gym):\n",
    "    index_to_check = indices_with_gym[test_index]\n",
    "    true_columns = [col for col in gym_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected gym features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_gym)} rows with gym features detected; test_index {test_index} is out of range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "addf104f-78bb-432e-a5fc-932905512abc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.175748Z",
     "start_time": "2025-07-13T13:16:40.172243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8898, 260)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5311fb3-170b-4f97-ae68-bb69a131c406",
   "metadata": {},
   "source": [
    "### Square meters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "caff7c82-8dfb-4423-9056-13c721d21692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.272733Z",
     "start_time": "2025-07-13T13:16:40.268467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract size in square meters\n",
    "def extract_square_meters(text):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    match = re.search(r\"\\b(\\d{1,3})\\s?(m2|m²|sqm|square meter|qm|quadratmeter)\\b\", text.lower())\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Apply to both 'name' and 'description', preferring 'name' first if both are present\n",
    "def get_size_from_name_or_description(row):\n",
    "    name_size = extract_square_meters(row[\"name\"])\n",
    "    if name_size:\n",
    "        return name_size\n",
    "    return extract_square_meters(row[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6d53e644-59f3-4f30-9143-1fa83762f48a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.492447Z",
     "start_time": "2025-07-13T13:16:40.334816Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"sqm\"] = df.apply(get_size_from_name_or_description, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cfd4b9ff-6075-4a3a-9a9e-c0088a9d5696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.539980Z",
     "start_time": "2025-07-13T13:16:40.535260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  name                                                                                                                                                                                                                                                                                                                                                                                                                              description    sqm\n",
      "137  LOVINGLY RESTORED 100qm APARTMENT  Our lovingly restored pre-war apartment in the famouse Kollwitzstraße, Berlin Prenzlauer Berg, holds up to 4 people in two separate bedrooms. Our apartment is located in the popular Kollwitzstrasse, one of the most beautiful areas of Berlin. Children are welcome-  while parties and smoking are not permitted. A four day minimum stay is required. For questions on availability, we would appreciate a short email from you...  100.0\n"
     ]
    }
   ],
   "source": [
    "df_check = df[df[\"sqm\"].notna()]\n",
    "df_check = df_check[[\"name\",\"description\",\"sqm\"]]\n",
    "# Select test index\n",
    "test_index = 15\n",
    "\n",
    "print(df_check[test_index:test_index+1].to_string(max_colwidth=2500))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75b1ce-50ab-492b-b5c9-f66c6368bade",
   "metadata": {},
   "source": [
    "### Fill with name and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "82ef8c41-d269-4810-b896-a85f2ae39a76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.596623Z",
     "start_time": "2025-07-13T13:16:40.594379Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# def fill_features_from_name_and_description(df):\n",
    "#     # Patterns for each column (EN + DE)\n",
    "#     feature_patterns = {\n",
    "#         \"has_backyard\": r\"\\b(backyard|garten|hof)\\b\",\n",
    "#         \"backyard_shared\": r\"\\b(shared backyard|gemeinschaftsgarten)\\b\",\n",
    "#         \"backyard_fully_fenced\": r\"\\b(fully fenced backyard|eingezäunter garten|komplett umzäunt)\\b\",\n",
    "#         \"has_balcony\": r\"\\b(balcony|balkon)\\b\",\n",
    "#         \"has_hottub\": r\"\\b(hot tub|whirlpool|jacuzzi)\\b\",\n",
    "#         \"private_entrance\": r\"\\b(private entrance|eigener eingang)\\b\",\n",
    "#         \"shared_entrance\": r\"\\b(shared entrance|geteilten eingang|geteilter eingang)\\b\",\n",
    "#         \"workspace\": r\"\\b(workspace|arbeitsplatz|schreibtisch|arbeitsbereich)\\b\",\n",
    "#         \"outdoor_pool_shared\": r\"\\b(shared outdoor pool|gemeinschaftspool)\\b\",\n",
    "#         \"outdoor_pool_private\": r\"\\b(private outdoor pool|eigener pool|privatpool)\\b\",\n",
    "#     }\n",
    "\n",
    "#     for feature, pattern in feature_patterns.items():\n",
    "#         regex = re.compile(pattern, flags=re.IGNORECASE)\n",
    "#         df[feature] = df.apply(\n",
    "#             lambda row: bool(regex.search(\n",
    "#                 f\"{str(row.get('name', ''))} {str(row.get('description', ''))}\"\n",
    "#             )),\n",
    "#             axis=1\n",
    "#         )\n",
    "\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d29e982a-84f7-4a2c-b441-7d50be7f8c0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.652569Z",
     "start_time": "2025-07-13T13:16:40.651227Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = fill_features_from_name_and_description(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b29ef4-456b-4c61-8551-75e6ff5775ab",
   "metadata": {},
   "source": [
    "#### Distance to center "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aa97717d-7899-4958-a6eb-7fbe6bbf3fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.715422Z",
     "start_time": "2025-07-13T13:16:40.705496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       longitude  latitude  distance_to_center\n",
      "7074    13.40584  52.51937            0.090209\n",
      "6361    13.40517  52.52113            0.126176\n",
      "1426    13.40392  52.51898            0.134921\n",
      "8733    13.40514  52.52126            0.140425\n",
      "13018   13.40516  52.52139            0.154940\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define Berlin center coordinates\n",
    "berlin_lat = 52.5200\n",
    "berlin_lon = 13.4050\n",
    "\n",
    "# Haversine distance function\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth's radius in km\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "\n",
    "    a = np.sin(delta_phi / 2.0) ** 2 + \\\n",
    "        np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0) ** 2\n",
    "\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Compute distance to Berlin center and create the new column\n",
    "df['distance_to_center'] = haversine(df['latitude'], df['longitude'], berlin_lat, berlin_lon)\n",
    "# Select relevant columns\n",
    "display_cols = ['longitude', 'latitude', 'distance_to_center']\n",
    "\n",
    "# Sort by distance_to_center\n",
    "df_sorted = df[display_cols].sort_values(by='distance_to_center', ascending=True)\n",
    "\n",
    "# Display cleanly\n",
    "print(df_sorted[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a234b2e-292a-4ba7-b4c6-68185804c40f",
   "metadata": {},
   "source": [
    "#### Distance to ubahn stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "95864c8d-854b-427c-9ebe-f8f0b73f7de5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.793375Z",
     "start_time": "2025-07-13T13:16:40.791170Z"
    }
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import re\n",
    "# from geopy.distance import geodesic\n",
    "\n",
    "# # Function to convert DMS to decimal degrees\n",
    "# def dms_to_decimal(degrees, minutes, seconds, direction):\n",
    "#     decimal = float(degrees) + float(minutes) / 60 + float(seconds) / 3600\n",
    "#     if direction in ['S', 'W']:  # South and West should be negative\n",
    "#         decimal = -decimal\n",
    "#     return decimal\n",
    "\n",
    "# # URL of the Wikipedia page\n",
    "# url = 'https://de.wikipedia.org/wiki/Liste_der_Berliner_U-Bahnh%C3%B6fe'\n",
    "\n",
    "# # Fetch the page content\n",
    "# response = requests.get(url)\n",
    "# soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# # Get the entire text of the page\n",
    "# page_text = soup.get_text()\n",
    "\n",
    "# # Define a regular expression pattern for coordinates\n",
    "# coordinate_pattern = r'(\\d{1,3})°\\s(\\d{1,2})′\\s(\\d{1,2})″\\s([NS]),\\s(\\d{1,3})°\\s(\\d{1,2})′\\s(\\d{1,2})″\\s([EO])'\n",
    "\n",
    "# # Find all matches in the page text\n",
    "# coordinates = re.findall(coordinate_pattern, page_text)\n",
    "\n",
    "# list_coordinates = []\n",
    "\n",
    "# # Convert the found coordinates to decimal degrees and print them\n",
    "# for coord in coordinates:\n",
    "#     # Latitude\n",
    "#     lat_deg, lat_min, lat_sec, lat_dir = coord[0], coord[1], coord[2], coord[3]\n",
    "#     lat_decimal = dms_to_decimal(lat_deg, lat_min, lat_sec, lat_dir)\n",
    "    \n",
    "#     # Longitude\n",
    "#     lon_deg, lon_min, lon_sec, lon_dir = coord[4], coord[5], coord[6], coord[7]\n",
    "    \n",
    "#     lon_decimal = dms_to_decimal(lon_deg, lon_min, lon_sec, lon_dir)\n",
    "#     list_coordinates.append((lat_decimal,lon_decimal))\n",
    "#     # Print the results\n",
    "#     #print(f\"Latitude: {lat_decimal}, Longitude: {lon_decimal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1434f10b-45a6-42c8-a96f-63f4984df986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.850717Z",
     "start_time": "2025-07-13T13:16:40.848474Z"
    }
   },
   "outputs": [],
   "source": [
    "# def minimum_distance_to_ubahn(row):\n",
    "#     # Get the coordinates of the listing\n",
    "#     listing_coords = (row['latitude'], row['longitude'])\n",
    "\n",
    "    \n",
    "#     # Calculate the distance to each U-Bahn station\n",
    "#     distances = [geodesic(listing_coords, ubahn).kilometers for ubahn in list_coordinates]\n",
    "    \n",
    "#     # Return the minimum distance\n",
    "#     return min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "24d9b517-9b6f-411d-b3e1-c5263521567c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.919013Z",
     "start_time": "2025-07-13T13:16:40.916146Z"
    }
   },
   "outputs": [],
   "source": [
    "# This takes a while\n",
    "# df[\"distance_ubahn\"] = df.apply(minimum_distance_to_ubahn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d781c879-3fba-4219-984d-b0859cdf54fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:40.981180Z",
     "start_time": "2025-07-13T13:16:40.978778Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(df[[\"latitude\", \"longitude\", \"distance_ubahn\"]].sort_values(by=\"distance_ubahn\", ascending=True).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1b48d-fd3b-4575-b7ba-995cbe75a7c4",
   "metadata": {},
   "source": [
    "#### Host lives in Berlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "021644f7-9dcb-4af3-83bd-078e08f0930b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:41.045028Z",
     "start_time": "2025-07-13T13:16:41.037285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1         True\n",
       "2         True\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "13940    False\n",
       "13941    False\n",
       "13942     True\n",
       "13943    False\n",
       "13944     True\n",
       "Name: host_in_berlin, Length: 8898, dtype: bool"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"host_in_berlin\"] = df[\"host_location\"].astype(str).str.contains(\"berlin\", case=False, na=False)\n",
    "df[\"host_in_berlin\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fedd3d2-7eec-44b9-b9ab-5d82d71f9847",
   "metadata": {},
   "source": [
    "#### Make host neighbourhood numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bfea705d-e4f3-4540-8c20-5de7803222a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:42.901125Z",
     "start_time": "2025-07-13T13:16:41.152668Z"
    }
   },
   "outputs": [],
   "source": [
    "neighbourhood_coords = {\n",
    "    \"Prenzlauer Berg\": (13.424, 52.538),\n",
    "    \"Kreuzberg\": (13.403, 52.499),\n",
    "    \"Neukölln\": (13.438, 52.480),\n",
    "    \"Charlottenburg\": (13.291, 52.505),\n",
    "    \"Friedrichshain\": (13.454, 52.515),\n",
    "    \"Mitte\": (13.400, 52.520),\n",
    "    \"Wedding\": (13.363, 52.552),\n",
    "    \"Schöneberg\": (13.356, 52.483),\n",
    "    \"Tiergarten\": (13.353, 52.516),\n",
    "    \"Wilmersdorf\": (13.308, 52.487),\n",
    "    \"Moabit\": (13.339, 52.530),\n",
    "    \"Tempelhof\": (13.385, 52.468),\n",
    "    \"Lichtenberg\": (13.499, 52.515),\n",
    "    \"Treptow\": (13.471, 52.480),\n",
    "    \"Steglitz\": (13.326, 52.456),\n",
    "    \"Marzahn\": (13.545, 52.545),\n",
    "    \"Pankow\": (13.401, 52.569),\n",
    "    \"Reinickendorf\": (13.334, 52.584),\n",
    "    \"Spandau\": (13.206, 52.535),\n",
    "}\n",
    "# Function to map neighbourhood to coordinates\n",
    "def get_neighbourhood_coords(neighbourhood):\n",
    "    if pd.isna(neighbourhood):\n",
    "        return pd.Series({\"longitude_neighbourhood\": None, \"latitude_neighbourhood\": None})\n",
    "    coords = neighbourhood_coords.get(neighbourhood.strip())\n",
    "    if coords:\n",
    "        lon, lat = coords\n",
    "        return pd.Series({\"longitude_neighbourhood\": lon, \"latitude_neighbourhood\": lat})\n",
    "    else:\n",
    "        return pd.Series({\"longitude_neighbourhood\": None, \"latitude_neighbourhood\": None})\n",
    "\n",
    "# Apply to df\n",
    "df[[\"longitude_host_neighbourhood\", \"latitude_host_neighbourhood\"]] = df[\"host_neighbourhood\"].apply(get_neighbourhood_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "074c2d66-ff0e-4ed8-b8cc-567d93a922f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:43.069318Z",
     "start_time": "2025-07-13T13:16:43.063235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   host_neighbourhood  longitude_host_neighbourhood  \\\n",
      "0     Prenzlauer Berg                        13.424   \n",
      "1     Prenzlauer Berg                        13.424   \n",
      "2     Prenzlauer Berg                        13.424   \n",
      "3           Kreuzberg                        13.403   \n",
      "4          Copacabana                           NaN   \n",
      "5           Kreuzberg                        13.403   \n",
      "7               Mitte                        13.400   \n",
      "9     Prenzlauer Berg                        13.424   \n",
      "10    Prenzlauer Berg                        13.424   \n",
      "11        Wilmersdorf                        13.308   \n",
      "\n",
      "    longitude_host_neighbourhood  \n",
      "0                         13.424  \n",
      "1                         13.424  \n",
      "2                         13.424  \n",
      "3                         13.403  \n",
      "4                            NaN  \n",
      "5                         13.403  \n",
      "7                         13.400  \n",
      "9                         13.424  \n",
      "10                        13.424  \n",
      "11                        13.308  \n"
     ]
    }
   ],
   "source": [
    "print(df[[\"host_neighbourhood\", \"longitude_host_neighbourhood\", \"longitude_host_neighbourhood\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9170b311-9564-4ffe-a363-bbd2c5499d2c",
   "metadata": {},
   "source": [
    "#### Make host response time numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "971e43ca-c481-4b29-a8e2-b719da2cf679",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:43.194334Z",
     "start_time": "2025-07-13T13:16:43.185624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    host_response_time  host_response_time_numeric\n",
      "0         within a day                        24.0\n",
      "1   a few days or more                        96.0\n",
      "2   within a few hours                         3.0\n",
      "4       within an hour                         1.0\n",
      "7   within a few hours                         3.0\n",
      "9   within a few hours                         3.0\n",
      "10      within an hour                         1.0\n",
      "11  within a few hours                         3.0\n",
      "16      within an hour                         1.0\n",
      "17      within an hour                         1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define mapping dictionary\n",
    "response_time_mapping = {\n",
    "    \"within an hour\": 1,\n",
    "    \"within a few hours\": 3,\n",
    "    \"within a day\": 24,\n",
    "    \"within a few days\": 72,\n",
    "    \"a few days or more\": 96\n",
    "}\n",
    "\n",
    "# Clean, lower, and map\n",
    "df[\"host_response_time_numeric\"] = (\n",
    "    df[\"host_response_time\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .map(response_time_mapping)\n",
    ")\n",
    "\n",
    "# Convert 'object' dtype to numeric explicitly\n",
    "df[\"host_response_time_numeric\"] = pd.to_numeric(df[\"host_response_time_numeric\"], errors='coerce')\n",
    "print(df[[\"host_response_time\", \"host_response_time_numeric\"]].dropna().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d9e7c334-fcaa-4a4f-b274-0530ec576dfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:43.255389Z",
     "start_time": "2025-07-13T13:16:43.253687Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Make host response rate, host acceptence rate numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2f853a7a-2e46-4c09-94c0-cf2eb8bb44e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:43.331088Z",
     "start_time": "2025-07-13T13:16:43.318897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove '%' and convert to numeric\n",
    "df[\"host_response_rate_numeric\"] = (\n",
    "    df[\"host_response_rate\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(\"%\", \"\", regex=False)\n",
    "    .replace(\"nan\", np.nan)  # in case of 'nan' strings\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "df[\"host_acceptance_rate_numeric\"] = (\n",
    "    df[\"host_acceptance_rate\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(\"%\", \"\", regex=False)\n",
    "    .replace(\"nan\", np.nan)\n",
    "    .astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69972602-329b-4e60-9854-bdf72beb7b41",
   "metadata": {},
   "source": [
    "### Remove unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "15468e3b-50c5-46ee-bf5c-69623eaca2fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:43.398076Z",
     "start_time": "2025-07-13T13:16:43.395420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8898, 268)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3eee8a3a-3f88-42f2-9c27-3602a24c7dec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:43.488640Z",
     "start_time": "2025-07-13T13:16:43.485810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id listing_url scrape_id last_scraped source name description neighborhood_overview picture_url host_id host_url host_name host_since host_location host_about host_response_time host_response_rate host_acceptance_rate host_is_superhost host_thumbnail_url host_picture_url host_neighbourhood host_listings_count host_total_listings_count host_verifications host_has_profile_pic host_identity_verified neighbourhood neighbourhood_cleansed neighbourhood_group_cleansed latitude longitude property_type room_type accommodates bathrooms bathrooms_text bedrooms beds amenities price minimum_nights maximum_nights minimum_minimum_nights maximum_minimum_nights minimum_maximum_nights maximum_maximum_nights minimum_nights_avg_ntm maximum_nights_avg_ntm calendar_updated has_availability availability_30 availability_60 availability_90 availability_365 calendar_last_scraped number_of_reviews number_of_reviews_ltm number_of_reviews_l30d availability_eoy number_of_reviews_ly estimated_occupancy_l365d estimated_revenue_l365d first_review last_review review_scores_rating review_scores_accuracy review_scores_cleanliness review_scores_checkin review_scores_communication review_scores_location review_scores_value license instant_bookable calculated_host_listings_count calculated_host_listings_count_entire_homes calculated_host_listings_count_private_rooms calculated_host_listings_count_shared_rooms reviews_per_month has_refrigerator refrigerator_shared refrigerator_vestel refrigerator_samsung refrigerator_severin refrigerator_miele refrigerator_smeg refrigerator_haier refrigerator_gaggenau refrigerator_lg refrigerator_electrolux refrigerator_whirlpool refrigerator_neff refrigerator_amazon refrigerator_ikea refrigerator_panasonic refrigerator_beko refrigerator_liebherr refrigerator_gorenje refrigerator_aeg refrigerator_bosch refrigerator_zanussi refrigerator_siemens refrigerator_sharp refrigerator_bomann refrigerator_teka refrigerator_amica has_oven oven_smeg oven_neff oven_siemens oven_electrolux oven_whirlpool oven_panasonic oven_aeg oven_bosch oven_miele oven_haier oven_ikea oven_teka oven_gaggenau oven_zanussi oven_beko has_stove stove_bosch stove_smeg stove_siemens stove_gas stove_zanussi stove_electric stove_beko stove_ikea stove_gaggenau stove_whirlpool stove_aeg stove_panasonic stove_miele stove_neff stove_electrolux stove_haier stove_induction stove_teka has_sound_system sound_lg sound_jbl sound_pioneer sound_bose sound_teufel sound_bang_olufsen sound_sonos sound_marshall sound_onkyo sound_yamaha sound_panasonic sound_denon sound_philips sound_sony sound_samsung has_coffee_maker coffee_espresso coffee_french_plus coffee_nespresso pour_over_coffee has_exercise_equipment exercise_equipment_free_weights exercise_equipment_elliptical exercise_equipment_stationary_bike exercise_equipment_yoga_mat exercise_equipment_workout_bench exercise_equipment_treadmill has_game_console ps2 ps3 ps4 ps5 xbox360 xboxone nintendoswitch wii has_tv tv_size_inch has_streaming_provider streaming_netflix streaming_amazon_prime_video streaming_apple_tv streaming_disney_plus has_clothing_storage clothing_storage_closet clothing_storage_wardrobe clothing_storage_walk_in has_parking parking_on_premises parking_off_premises parking_free_carport parking_free_driveway parking_free_garage parking_free_residential_garage parking_free_street parking_paid_garage parking_paid_lot parking_paid parking_paid_street has_outdoor outdoor_pool_shared outdoor_pool_private outdoor_dining_area outdoor_furniture outdoor_kitchen outdoor_playground has_bath_bed_game_items bath_item_shampoo bath_item_body_soap bath_item_conditioner kitchen_item_baking_sheet bed_item_bed_linens game_item_games has_wifi wifi_speed_mbps has_backyard backyard_shared backyard_fully_fenced has_balcony has_heating has_central_heating has_hottub has_bathtub has_washer washer_paid washer_in_building has_dryer dryer_paid dryer_in_building housekeeping_included housekeeping_available_at_cost baby_bath baby_monitor baby_safety children_books_and_toys crib high_chair luggage_dropoff_allowed long_term_stays_allowed air_conditioning pets_allowed ping_pong_table host_greets_you pool_table private_entrance workspace beach_view city_skyline_view desert_view garden_view pool_view gym_private_in_building gym_private_nearby gym_shared_in_building gym_shared_nearby gym_private gym_shared gym sqm distance_to_center host_in_berlin longitude_host_neighbourhood latitude_host_neighbourhood host_response_time_numeric host_response_rate_numeric host_acceptance_rate_numeric "
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    print(c+\" \",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0a31c7a5-a824-4107-8155-81a48097e905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:43.572654Z",
     "start_time": "2025-07-13T13:16:43.569125Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "\n",
    "    # Cheating\n",
    "    \"estimated_revenue_l365d\",  \n",
    "    \n",
    "    # We have these transformed/in some other variable\n",
    "    \"host_response_time\",\"host_response_rate\",\"amenities\",\"description\",\"host_location\",\"host_neighbourhood\",\"neighborhood_overview\", \"neighbourhood\",\"bathrooms_text\",\"name\",\"host_about\",\n",
    "\n",
    "    \n",
    "    \"host_total_listings_count \",\"calculated_host_listings_count_entire_homes\",\n",
    "    \"number_of_reviews_ly\",\"number_of_reviews_ltm\",\"first_review\", \"last_review\",\n",
    "\n",
    "    \"minimum_minimum_nights\", \"maximum_maximum_nights\",\"maximum_nights_avg_ntm\",\"maximum_maximum_nights\",\"minimum_maximum_nights \",\"maximum_minimum_nights\",\"minimum_maximum_nights\",\"minimum_nights_avg_ntm\",\n",
    "    \"availability_60\",\"availability_90\",\"availability_365\",\"availability_eoy\",\n",
    "    \n",
    "\n",
    "    # Very likely not relevant/ allready have\n",
    "    \"license\",\"host_name\", \"host_since\",\"host_has_profile_pic\",\"has_availability\",  \"host_verifications\",    \"calendar_updated\",      \n",
    "    \n",
    "    # Definitly not relevant\n",
    "\n",
    "    # URLS\n",
    "    \"listing_url\", \"picture_url\", \"host_thumbnail_url\", \"host_picture_url\",\"host_url\",\n",
    "    \n",
    "    # Scraping stuff\n",
    "    \"scrape_id\", \"last_scraped\", \"source\", \"calendar_last_scraped\",\"scrape_id\",\n",
    "    # IDS\n",
    "     \"host_id\" \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ada15cf2-04dd-4efe-ac32-c0dd6dac3f5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:43.636187Z",
     "start_time": "2025-07-13T13:16:43.633888Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"instant_bookable\",\"host_is_superhost\",\"host_acceptance_rate\",\"host_identity_verified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "03f1a2a5-ab2f-4642-90fa-f39c3b4d2a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:43.720528Z",
     "start_time": "2025-07-13T13:16:43.692861Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=[col for col in columns_to_remove if col in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e2b6b80b-4860-458d-aa67-829aa8a86154",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:43.779197Z",
     "start_time": "2025-07-13T13:16:43.776713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8898, 224)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b92659-8ed9-49a6-8f79-52358802d36b",
   "metadata": {},
   "source": [
    "### Convert Text/Object to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "32fbe7eb-98f2-41ca-8ada-7d6f6c3f9f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:43.934359Z",
     "start_time": "2025-07-13T13:16:43.923395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟩 Boolean columns: 180\n",
      "🟦 Categorical columns: 0\n",
      "🟧 Object/String columns: 8\n",
      "🟨 Numeric columns: 36\n",
      "🟥 Other columns: 0\n"
     ]
    }
   ],
   "source": [
    "# Count and print the number of columns by type\n",
    "bool_cols = df.select_dtypes(include='bool').columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['category']).columns.tolist()\n",
    "str_cols = df.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "num_cols = df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "other_cols = [col for col in df.columns if col not in bool_cols + cat_cols + str_cols + num_cols]\n",
    "\n",
    "print(f\"🟩 Boolean columns: {len(bool_cols)}\")\n",
    "print(f\"🟦 Categorical columns: {len(cat_cols)}\")\n",
    "print(f\"🟧 Object/String columns: {len(str_cols)}\")\n",
    "print(f\"🟨 Numeric columns: {len(num_cols)}\")\n",
    "print(f\"🟥 Other columns: {len(other_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "42c740e6-b99e-4af4-a364-629a80d32a72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:44.030625Z",
     "start_time": "2025-07-13T13:16:44.021756Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "cols_to_convert = [\"instant_bookable\", \"host_is_superhost\", \"host_acceptance_rate\", \"host_identity_verified\"]\n",
    "\n",
    "# Convert 'true'/'false' strings to actual booleans\n",
    "df[cols_to_convert] = df[cols_to_convert].apply(lambda col: col.str.lower() == 't')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "204cf2d0-089c-4b08-819a-6d22cd3647fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:44.095797Z",
     "start_time": "2025-07-13T13:16:44.089354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟩 Boolean columns: 184\n",
      "🟦 Categorical columns: 0\n",
      "🟧 Object/String columns: 4\n",
      "🟨 Numeric columns: 36\n",
      "🟥 Other columns: 0\n"
     ]
    }
   ],
   "source": [
    "# Count and print the number of columns by type\n",
    "bool_cols = df.select_dtypes(include='bool').columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['category']).columns.tolist()\n",
    "str_cols = df.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "num_cols = df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "other_cols = [col for col in df.columns if col not in bool_cols + cat_cols + str_cols + num_cols]\n",
    "\n",
    "print(f\"🟩 Boolean columns: {len(bool_cols)}\")\n",
    "print(f\"🟦 Categorical columns: {len(cat_cols)}\")\n",
    "print(f\"🟧 Object/String columns: {len(str_cols)}\")\n",
    "print(f\"🟨 Numeric columns: {len(num_cols)}\")\n",
    "print(f\"🟥 Other columns: {len(other_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c417d5-7ab3-4fb2-a367-7bdddd422a3d",
   "metadata": {},
   "source": [
    "### Drop where no Review,bathroom,bedroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "49ab82e7-e679-440a-8e93-61c62bbf47b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:44.308532Z",
     "start_time": "2025-07-13T13:16:44.298961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8898, 224)\n",
      "(6845, 224)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df[df[\"review_scores_rating\"].notna()]\n",
    "df = df[df[\"bathrooms\"].notna()]\n",
    "df = df[df[\"bedrooms\"].notna()]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce0ca6e-6d67-4394-b613-5d307da3b944",
   "metadata": {},
   "source": [
    "### Drop IDS by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9342919a-0bb2-4d92-bdf9-63d002fe119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this does not infer Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ac41c4e2-8aa8-400f-b172-e2615d9aa865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:44.506617Z",
     "start_time": "2025-07-13T13:16:44.498028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6831, 224)\n",
      "(6831, 224)\n"
     ]
    }
   ],
   "source": [
    "# List of IDs to drop\n",
    "ids_to_drop = [\n",
    "    2860420,\n",
    "    7807397,\n",
    "    41787739,\n",
    "    928290731641806731,\n",
    "    967963843443094544,\n",
    "    1234474294833419521,\n",
    "    1234483190089885723,\n",
    "    28432988,\n",
    "    559822192883775161,\n",
    "    559824222713920928,\n",
    "    6663931,\n",
    "    29695826,\n",
    "    1234483190089885723, # added\n",
    "    20109066,\n",
    "    38585015,\n",
    "    967963843443094544\n",
    "]\n",
    "\n",
    "# Drop rows with these IDs\n",
    "df = df[~df['id'].isin(ids_to_drop)].copy()\n",
    "print(df.shape)\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469d334-21db-451d-a536-3de48ce4e872",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "67b8b5acda660cad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:44.598839Z",
     "start_time": "2025-07-13T13:16:44.577577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 5464 rows\n",
      "Test set size: 1367 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split into train and test\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Confirm split\n",
    "print(f\"Train set size: {df_train.shape[0]} rows\")\n",
    "print(f\"Test set size: {df_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "884b07e9ae0c254c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:44.658379Z",
     "start_time": "2025-07-13T13:16:44.656554Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_id = df_train['id']\n",
    "df_test_id = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c1a9b36de0940be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:44.707191Z",
     "start_time": "2025-07-13T13:16:44.699536Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_id.to_csv('train_id.csv',index=False)\n",
    "df_test_id.to_csv('test_id.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "31ff93202fba79a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:44.763764Z",
     "start_time": "2025-07-13T13:16:44.761393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5464,), (1367,))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_id.shape, df_test_id.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b3993-7714-4565-b52b-0cb7ef0dbd22",
   "metadata": {},
   "source": [
    "# Add sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7cb62b8b-e165-44e0-89e8-ea98b83e6ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need the sentimental file for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c6cd733b-d936-4d22-9597-a65f16469341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:47.308369Z",
     "start_time": "2025-07-13T13:16:44.815224Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_features_train = pd.read_csv(\"features_train.csv\")\n",
    "# columns_to_remove = [\"price\"]\n",
    "\n",
    "# df_features_train = df_features_train.drop(columns=[col for col in columns_to_remove if col in df_features_train.columns])\n",
    "\n",
    "# df_train= pd.merge(df_train, df_features_train, on='id', how='left')\n",
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057150fcd29656",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:48.051416Z",
     "start_time": "2025-07-13T13:16:47.458349Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_features_test = pd.read_csv(\"features_test.csv\")\n",
    "# columns_to_remove = [\"price\"]\n",
    "\n",
    "# df_features_test = df_features_test.drop(columns=[col for col in columns_to_remove if col in df_features_test.columns])\n",
    "\n",
    "# df_test= pd.merge(df_test, df_features_test, on='id', how='left')\n",
    "# df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dea86b-1549-4903-8bd4-f4f683f66170",
   "metadata": {},
   "source": [
    "### Save Data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9fd0a7fd-8880-4a4f-ba43-513f604d6e37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:16:48.779893Z",
     "start_time": "2025-07-13T13:16:48.499098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟩 Boolean columns: 184\n",
      "🟦 Categorical columns: 0\n",
      "🟧 Object/String columns: 4\n",
      "🟨 Numeric columns: 36\n",
      "🟥 Other columns: 0\n",
      "🟦 Remaining string/object columns in df: ['neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'property_type', 'room_type']\n"
     ]
    }
   ],
   "source": [
    "# Count and print the number of columns by type\n",
    "bool_cols = df_train.select_dtypes(include='bool').columns.tolist()\n",
    "cat_cols = df_train.select_dtypes(include=['category']).columns.tolist()\n",
    "str_cols = df_train.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "num_cols = df_train.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "other_cols = [col for col in df_train.columns if col not in bool_cols + cat_cols + str_cols + num_cols]\n",
    "\n",
    "print(f\"🟩 Boolean columns: {len(bool_cols)}\")\n",
    "print(f\"🟦 Categorical columns: {len(cat_cols)}\")\n",
    "print(f\"🟧 Object/String columns: {len(str_cols)}\")\n",
    "print(f\"🟨 Numeric columns: {len(num_cols)}\")\n",
    "print(f\"🟥 Other columns: {len(other_cols)}\")\n",
    "# Final check\n",
    "str_obj_cols = df_train.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "print(f\"🟦 Remaining string/object columns in df: {str_obj_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96aacb-b7fa-4f1e-8fbd-b5281904afa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:17:03.288053Z",
     "start_time": "2025-07-13T13:16:48.846071Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train.to_csv(\"train_final.csv\", index=False)\n",
    "# df_test.to_csv(\"test_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9abf9ee54f12adc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:17:33.393384Z",
     "start_time": "2025-07-13T13:17:33.389370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5464, 224), (1367, 224))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
